{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a86ac80-c99a-4e43-80ed-e04f4857d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.9/dist-packages (0.3.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (9.2.0)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (0.7.1)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (0.7.4)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (0.13.1+cu116)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (4.64.1)\n",
      "Requirement already satisfied: timm==0.9.2 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (0.9.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12.1+cu116)\n",
      "Requirement already satisfied: munch in /usr/local/lib/python3.9/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.12.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.9/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: neptune in /usr/local/lib/python3.9/dist-packages (1.8.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from neptune) (23.0)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /usr/local/lib/python3.9/dist-packages (from neptune) (3.0.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/lib/python3/dist-packages (from neptune) (0.18.2)\n",
      "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (11.0.3)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (3.2.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from neptune) (5.9.4)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (1.3.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from neptune) (1.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from neptune) (1.14.0)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (0.57.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (2.28.2)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.9/dist-packages (from neptune) (9.2.0)\n",
      "Requirement already satisfied: boto3>=1.28.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (1.28.85)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (8.1.3)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.9/dist-packages (from neptune) (3.1.30)\n",
      "Requirement already satisfied: PyJWT in /usr/local/lib/python3.9/dist-packages (from neptune) (2.8.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from neptune) (1.26.14)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.85 in /usr/local/lib/python3.9/dist-packages (from boto3>=1.28.0->neptune) (1.31.85)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3>=1.28.0->neptune) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from boto3>=1.28.0->neptune) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (4.4.0)\n",
      "Requirement already satisfied: monotonic in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.6)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (2.8.2)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.0.4)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (5.4.1)\n",
      "Requirement already satisfied: simplejson in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (3.19.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=2.0.8->neptune) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->neptune) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.20.0->neptune) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.20.0->neptune) (2019.11.28)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from swagger-spec-validator>=2.7.4->neptune) (4.17.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neptune) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas->neptune) (1.23.4)\n",
      "Requirement already satisfied: jsonref in /usr/local/lib/python3.9/dist-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune) (1.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (18.2.0)\n",
      "Requirement already satisfied: fqdn in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.5.1)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (2.4)\n",
      "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.1.4)\n",
      "Requirement already satisfied: isoduration in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (20.11.0)\n",
      "Requirement already satisfied: uri-template in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.3.0)\n",
      "Requirement already satisfied: rfc3987 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.3.8)\n",
      "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.9/dist-packages (from arrow>=0.15.0->isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune) (2.8.19.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (1.2.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.23.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.12.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: albumentations in /usr/local/lib/python3.9/dist-packages (1.3.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.23.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.9.2)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (4.8.1.78)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (1.1.2)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.1.23.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2.25.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install segmentation_models_pytorch \n",
    "!pip install neptune\n",
    "!pip install torchmetrics\n",
    "!pip install albumentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85aa78b5-8605-4b7e-ad76-c342f86b5505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import segmentation_models_pytorch as smp\n",
    "import neptune\n",
    "from neptune.types import File\n",
    "\n",
    "from torchmetrics.functional.classification import dice as calc_dice_score\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7dd68c-6f39-4609-9e1a-75d9314bc9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21830/2663222614.py:15: NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/Kernel-bois/computer-vision/e/CV-151\n"
     ]
    }
   ],
   "source": [
    "# Define a custom dataset class\n",
    "# Training params\n",
    "BATCH_SIZE = 13\n",
    "EPOCHS = 110\n",
    "LEARNING_RATE = 0.0000367\n",
    "\n",
    "# Model params\n",
    "ENCODER_NAME = \"resnet34\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "\n",
    "with open(\"/notebooks/Testing/NEPTUNE_API_TOKEN.txt\", \"r\") as file:\n",
    "    # Read the entire content of the file into a string\n",
    "    token = file.read()\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"Kernel-bois/computer-vision\",\n",
    "    api_token=token,\n",
    ")\n",
    "run_id = run[\"sys/id\"].fetch()\n",
    "\n",
    "# Create the model\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER_NAME,           # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=ENCODER_WEIGHTS,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                        # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                            # model output channels (number of classes in your dataset)\n",
    "    )\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)\n",
    "#Scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "run_name = \"MODEL-\" + model.__class__.__name__ + ENCODER_NAME + str(run_id)\n",
    "\n",
    "save_path = str(run_id) + \"/\"\n",
    "os.makedirs(save_path)\n",
    "\n",
    "# Proper directories\n",
    "TRAIN_DATA_DIR = '/notebooks/image_segmentation/network/image_data_all/train'\n",
    "VAL_DATA_DIR = '/notebooks/image_segmentation/network/image_data_all/val'\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "# criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=False)  # Binary dice Loss for binary segmentation\n",
    "# criterion = smp.losses.SoftBCEWithLogitsLoss()  # Binary dice Loss for binary segmentation\n",
    "criterion = DiceBCELoss()  # Binary dice Loss for binary segmentation\n",
    "calc_iou = BinaryJaccardIndex().to(device)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"MODEL\": model.__class__.__name__,\n",
    "    \"BACKBONE\": ENCODER_NAME,\n",
    "    \"ENCODER_WEIGHTS\": ENCODER_WEIGHTS,\n",
    "    \"BATCH_SIZE\": str(BATCH_SIZE),\n",
    "    \"EPOCHS\": str(EPOCHS),\n",
    "    \"CRITERION\": criterion.__class__.__name__,\n",
    "    \"OPTIMIZER\": optimizer.__class__.__name__,\n",
    "    \"LEARNRATE\": str(LEARNING_RATE),\n",
    "    \"MODEL_NAME\": run_name,\n",
    "}\n",
    "\n",
    "run[\"params\"] = params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea045fa-5b8e-4173-ad61-1d6c1cfc52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform = None, target_size = (992, 416)):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "\n",
    "        self.image_folder = os.path.join(root_dir, 'images')\n",
    "        self.mask_folder = os.path.join(root_dir, 'masks')\n",
    "\n",
    "        self.images = os.listdir(self.image_folder)\n",
    "        self.masks = os.listdir(self.mask_folder)\n",
    "\n",
    "        assert len(self.images) == len(self.masks), \"Number of images and masks should be the same.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.images[idx])\n",
    "        if \"patient\" in self.images[idx]:\n",
    "            mask_path = os.path.join(self.mask_folder, \"segmentation_\" + self.images[idx][-7:])\n",
    "        else:\n",
    "            mask_path = os.path.join(self.mask_folder, \"target_seg_\" + self.images[idx][-7:])\n",
    "        \n",
    "        # Load images\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "\n",
    "        # Convert to tensors \n",
    "        tensor_image = torch.from_numpy(image)\n",
    "        tensor_image = tensor_image.permute(2, 0, 1)\n",
    "\n",
    "        tensor_mask = torch.from_numpy(mask)\n",
    "        tensor_mask = tensor_mask.permute(2, 0, 1) / 255\n",
    "        tensor_mask = tensor_mask[2:, :, :]\n",
    "        \n",
    "        # add padding\n",
    "        pad_height = max(self.target_size[0] - tensor_image.size(1), 0)\n",
    "        pad_width = max(self.target_size[1] - tensor_image.size(2), 0)\n",
    "\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        padded_image = transforms.functional.pad(tensor_image, (pad_left, pad_bottom, pad_right, pad_top), fill=255)\n",
    "        padded_mask = transforms.functional.pad(tensor_mask, (pad_left, pad_bottom, pad_right, pad_top), fill=0)\n",
    "\n",
    "        return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d066e50c-8736-49c2-a1b2-cafd60dcb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# Set up dataset and dataloader\n",
    "transform = A.Compose([])\n",
    "\n",
    "#transform = A.Compose([A.GaussNoise(p = 0.2), A.RandomGamma(p = 0.2), A.Sharpen(p=0.2),\n",
    "#                       A.Resize(width = np.random.randint(200, 416), height = np.random.randint(200,992), p = 0.2)])\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# ALL Transforms\n",
    "# A.CLAHE(p=0.2)\n",
    "# A.HorizontalFlip(p=0.5),\n",
    "# A.RandomGamma(p=0.2)\n",
    "# A.GridDistortion(p=0.2)\n",
    "# A.RandomBrightnessContrast(p=0.2)\n",
    "# A.Resize(width = np.random.randint(200, 416), height = np.random.randint(200,992), p = 0.2)\n",
    "# A.OneOf([ ],p=0.9) for more \n",
    "# A.Sharpen(p=0.2)\n",
    "# A.Blur(p=0.2)\n",
    "# A.RandomCrop(height = 200, width=200, p=0.2)\n",
    "# GaussNoise(p = 0.2)\n",
    "\n",
    "trainDataset = SegmentationDataset(root_dir=TRAIN_DATA_DIR, transform=transform)\n",
    "valDataset = SegmentationDataset(root_dir=VAL_DATA_DIR)\n",
    "\n",
    "train_loader = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(valDataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e995c-aab0-44fd-ab12-af8d056ae0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/420589072.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_masks_int = torch.tensor(val_masks, dtype=torch.int8)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/110], Train Loss: 1.8247190713882446, Validation Loss: 1.7104558944702148\n",
      "IOU: 0.01065882109105587, Dice Score: 0.02095317840576172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/110], Train Loss: 1.6140100955963135, Validation Loss: 1.5243184566497803\n",
      "IOU: 0.020627550780773163, Dice Score: 0.03998257964849472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/110], Train Loss: 1.5249232053756714, Validation Loss: 1.5278584957122803\n",
      "IOU: 0.06291592121124268, Dice Score: 0.11481727659702301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/110], Train Loss: 1.4748064279556274, Validation Loss: 1.4663931131362915\n",
      "IOU: 0.10031600296497345, Dice Score: 0.1770683079957962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/110], Train Loss: 1.4168775081634521, Validation Loss: 1.4175342321395874\n",
      "IOU: 0.12665539979934692, Dice Score: 0.21781054139137268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/110], Train Loss: 1.3917344808578491, Validation Loss: 1.3803331851959229\n",
      "IOU: 0.18144741654396057, Dice Score: 0.29516810178756714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/110], Train Loss: 1.3679026365280151, Validation Loss: 1.3558037281036377\n",
      "IOU: 0.20357978343963623, Dice Score: 0.3252891004085541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/110], Train Loss: 1.345407485961914, Validation Loss: 1.3571960926055908\n",
      "IOU: 0.1812358796596527, Dice Score: 0.2951108515262604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]          /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/110], Train Loss: 1.3215934038162231, Validation Loss: 1.3237907886505127\n",
      "IOU: 0.17658288776874542, Dice Score: 0.2894582450389862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/110], Train Loss: 1.3005708456039429, Validation Loss: 1.4328480958938599\n",
      "IOU: 0.2024664580821991, Dice Score: 0.3116248846054077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/110], Train Loss: 1.287680983543396, Validation Loss: 1.2779290676116943\n",
      "IOU: 0.24960562586784363, Dice Score: 0.3782554566860199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/110], Train Loss: 1.2711519002914429, Validation Loss: 1.2647461891174316\n",
      "IOU: 0.3075675368309021, Dice Score: 0.4430972635746002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/110], Train Loss: 1.2578096389770508, Validation Loss: 1.252870798110962\n",
      "IOU: 0.31852924823760986, Dice Score: 0.45545274019241333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/110], Train Loss: 1.2405598163604736, Validation Loss: 1.2370259761810303\n",
      "IOU: 0.3917141854763031, Dice Score: 0.5323654413223267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/110], Train Loss: 1.2232125997543335, Validation Loss: 1.245605230331421\n",
      "IOU: 0.35608261823654175, Dice Score: 0.4933839738368988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/110], Train Loss: 1.2091789245605469, Validation Loss: 1.207174301147461\n",
      "IOU: 0.38523241877555847, Dice Score: 0.524076521396637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/110], Train Loss: 1.2031294107437134, Validation Loss: 1.4368808269500732\n",
      "IOU: 0.13454392552375793, Dice Score: 0.22971530258655548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/110], Train Loss: 1.1892164945602417, Validation Loss: 1.1883124113082886\n",
      "IOU: 0.3551744520664215, Dice Score: 0.49328580498695374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/110], Train Loss: 1.1733943223953247, Validation Loss: 1.2414228916168213\n",
      "IOU: 0.060035042464733124, Dice Score: 0.11144056171178818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/110], Train Loss: 1.1680433750152588, Validation Loss: 1.1720243692398071\n",
      "IOU: 0.2918093800544739, Dice Score: 0.42608633637428284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/110], Train Loss: 1.1535311937332153, Validation Loss: 1.1602048873901367\n",
      "IOU: 0.375556617975235, Dice Score: 0.5147019624710083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/110], Train Loss: 1.1413488388061523, Validation Loss: 1.1476166248321533\n",
      "IOU: 0.4241347312927246, Dice Score: 0.5607422590255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/110], Train Loss: 1.159265160560608, Validation Loss: 1.246962308883667\n",
      "IOU: 0.13673552870750427, Dice Score: 0.2323029488325119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/110], Train Loss: 1.1286687850952148, Validation Loss: 1.130663514137268\n",
      "IOU: 0.39009517431259155, Dice Score: 0.527160108089447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/110], Train Loss: 1.115174651145935, Validation Loss: 1.1244146823883057\n",
      "IOU: 0.2980736196041107, Dice Score: 0.4368125796318054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/110], Train Loss: 1.1068310737609863, Validation Loss: 1.1153748035430908\n",
      "IOU: 0.32781094312667847, Dice Score: 0.4676799774169922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/110], Train Loss: 1.0984923839569092, Validation Loss: 1.1077708005905151\n",
      "IOU: 0.4008568823337555, Dice Score: 0.539330780506134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/110], Train Loss: 1.0895898342132568, Validation Loss: 1.0999451875686646\n",
      "IOU: 0.3959546387195587, Dice Score: 0.5321620106697083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/110], Train Loss: 1.0808212757110596, Validation Loss: 1.0923852920532227\n",
      "IOU: 0.41688767075538635, Dice Score: 0.5533701181411743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/110], Train Loss: 1.0742923021316528, Validation Loss: 1.0865488052368164\n",
      "IOU: 0.38199684023857117, Dice Score: 0.5224844217300415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/110], Train Loss: 1.065133810043335, Validation Loss: 1.0805078744888306\n",
      "IOU: 0.4304068982601166, Dice Score: 0.5634545087814331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/110], Train Loss: 1.055924654006958, Validation Loss: 1.072073221206665\n",
      "IOU: 0.39567962288856506, Dice Score: 0.5327767133712769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/110], Train Loss: 1.0493476390838623, Validation Loss: 1.069801688194275\n",
      "IOU: 0.4019598066806793, Dice Score: 0.539448082447052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/110], Train Loss: 1.042913794517517, Validation Loss: 1.066338300704956\n",
      "IOU: 0.0, Dice Score: 0.5250110030174255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/110], Train Loss: 1.0356889963150024, Validation Loss: 1.0545575618743896\n",
      "IOU: 0.0, Dice Score: 0.5510304570198059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/110], Train Loss: 1.0297703742980957, Validation Loss: 1.2611525058746338\n",
      "IOU: 0.0, Dice Score: 0.33567577600479126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/110], Train Loss: 1.0263772010803223, Validation Loss: 1.0448919534683228\n",
      "IOU: 0.41463595628738403, Dice Score: 0.5536563992500305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/110], Train Loss: 1.0139355659484863, Validation Loss: 1.035209059715271\n",
      "IOU: 0.3800840973854065, Dice Score: 0.5212694406509399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/110], Train Loss: 1.003511667251587, Validation Loss: 1.0274012088775635\n",
      "IOU: 0.39761000871658325, Dice Score: 0.5369656682014465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/110], Train Loss: 0.9978570342063904, Validation Loss: 1.0214585065841675\n",
      "IOU: 0.45416775345802307, Dice Score: 0.5872234106063843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/110], Train Loss: 0.9909974932670593, Validation Loss: 1.0141972303390503\n",
      "IOU: 0.43080735206604004, Dice Score: 0.5674703121185303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/110], Train Loss: 0.9822422862052917, Validation Loss: 1.00824773311615\n",
      "IOU: 0.4160084128379822, Dice Score: 0.5549716353416443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/10 [00:00<?, ?it/s]           /tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/110], Train Loss: 0.9704117774963379, Validation Loss: 1.0015987157821655\n",
      "IOU: 0.0, Dice Score: 0.5896446704864502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/110:   0%|          | 0/42 [00:00<?, ?it/s]/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_21830/850540683.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Epoch 44/110:  83%| | 35/42 [00:21<00:04,  1.72it/s]"
     ]
    }
   ],
   "source": [
    "# Train Loop\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = torch.tensor(0.0)\n",
    "    model.train()\n",
    "\n",
    "    # Use tqdm to add a progress bar\n",
    "    for images, masks in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{EPOCHS}', leave=False):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # outputs = torch.argmax(outputs, dim=1).unsqueeze(1).float()\n",
    "\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss += loss.detach().cpu()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    run[\"loss/train_loss\"].log(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = torch.tensor(0.0)\n",
    "    iou = torch.tensor(0.0)\n",
    "    dice_score = torch.tensor(0.0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in tqdm(val_loader, desc=f'Validation', leave=False):\n",
    "            val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "\n",
    "            model_outputs = model(val_images)\n",
    "\n",
    "            val_loss += criterion(model_outputs, val_masks).cpu()\n",
    "\n",
    "            val_masks_int = torch.tensor(val_masks, dtype=torch.int8)\n",
    "            dice_score += calc_dice_score(torch.sigmoid(model_outputs), val_masks_int, ignore_index=0).cpu()\n",
    "\n",
    "            iou += calc_iou(model_outputs, val_masks_int).cpu()\n",
    "\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    iou /= len(val_loader)\n",
    "    dice_score /= len(val_loader)\n",
    "\n",
    "    if torch.isnan(iou):\n",
    "        iou = torch.tensor(0.0)\n",
    "\n",
    "    run[\"loss/val_loss\"].log(val_loss)\n",
    "    run[\"val/iou\"].log(iou)\n",
    "    run[\"val/dice_score\"].log(dice_score)\n",
    "\n",
    "    torch.save(model.state_dict(), save_path + run_name + \"_EPOCH_\" + str(epoch) + '.pth')\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Train Loss: {train_loss}, Validation Loss: {val_loss}\\n\"\n",
    "          f\"IOU: {iou}, Dice Score: {dice_score}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), save_path + run_name + \"_FINAL\" + '.pth')\n",
    "run[f\"network/network_weights\"].upload(File(run_name + '.pth'))\n",
    "\n",
    "run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17303f4-c66d-408f-ab68-5dd53c365af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Declare an augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.RandomCrop(height = 200, width=200, p=1)\n",
    "])\n",
    "\n",
    "image_path = \"/notebooks/image_segmentation/network/image_data/train/images/patient_116.png\"\n",
    "mask_path = \"/notebooks/image_segmentation/network/image_data/train/masks/segmentation_116.png\" \n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "mask = cv2.imread(mask_path)\n",
    "\n",
    "transformed = transform(image=image, mask=mask)\n",
    "transformed_image = transformed['image']\n",
    "transformed_mask = transformed['mask']\n",
    "\n",
    "image_torch, mask_torch = convert_to_torch(image, mask)\n",
    "plot_image_and_mask(image_torch, mask_torch)\n",
    "    \n",
    "image_torch, mask_torch = convert_to_torch(transformed_image, transformed_mask)\n",
    "plot_image_and_mask(image_torch, mask_torch)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4f9b89-04d7-45a0-8ff2-68209fb468c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_mask(image, mask): \n",
    "    image = image/ 255.0\n",
    "    mask = mask\n",
    "\n",
    "    # Plot side by side with the mask and mask overlain\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Plot the original image\n",
    "    axes[0].imshow(image.permute(1, 2, 0))\n",
    "    axes[0].set_title('Original Image')\n",
    "\n",
    "    # Plot the mask\n",
    "    axes[1].imshow(mask.permute(1, 2, 0), cmap='viridis')\n",
    "    axes[1].set_title('Mask')\n",
    "\n",
    "    # Overlay the mask on the image\n",
    "    axes[2].imshow(image.permute(1, 2, 0))\n",
    "    axes[2].imshow(mask.permute(1, 2, 0), cmap='viridis', alpha=0.6)  # Set alpha to less than 1\n",
    "    axes[2].set_title('Mask Overlain on Image')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.show()\n",
    "\n",
    "def convert_to_torch(image, mask):\n",
    "    \n",
    "    tensor_image = torch.from_numpy(image)\n",
    "    tensor_image = tensor_image.permute(2,0, 1)\n",
    "\n",
    "    tensor_mask = torch.from_numpy(mask)\n",
    "    tensor_mask = tensor_mask.permute(2,0, 1) / 255\n",
    "    \n",
    "    tensor_mask = tensor_mask[2:, :, :]\n",
    "\n",
    "    # add padding\n",
    "    pad_height = max(992 - tensor_image.size(1), 0)\n",
    "    pad_width = max(416 - tensor_image.size(2), 0)\n",
    "\n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "\n",
    "    padded_image = transforms.functional.pad(tensor_image, (pad_left, pad_bottom, pad_right, pad_top), fill=255)\n",
    "    padded_mask = transforms.functional.pad(tensor_mask, (pad_left, pad_bottom, pad_right, pad_top), fill=0)\n",
    "\n",
    "\n",
    "    return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fdcdf84-3404-4379-87b0-655ef033cc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UnetPlusPlus:\n\tMissing key(s) in state_dict: \"encoder.stem.conv.weight\", \"encoder.stem.bn.weight\", \"encoder.stem.bn.bias\", \"encoder.stem.bn.running_mean\", \"encoder.stem.bn.running_var\", \"encoder.s1.b1.conv1.conv.weight\", \"encoder.s1.b1.conv1.bn.weight\", \"encoder.s1.b1.conv1.bn.bias\", \"encoder.s1.b1.conv1.bn.running_mean\", \"encoder.s1.b1.conv1.bn.running_var\", \"encoder.s1.b1.conv2.conv.weight\", \"encoder.s1.b1.conv2.bn.weight\", \"encoder.s1.b1.conv2.bn.bias\", \"encoder.s1.b1.conv2.bn.running_mean\", \"encoder.s1.b1.conv2.bn.running_var\", \"encoder.s1.b1.conv3.conv.weight\", \"encoder.s1.b1.conv3.bn.weight\", \"encoder.s1.b1.conv3.bn.bias\", \"encoder.s1.b1.conv3.bn.running_mean\", \"encoder.s1.b1.conv3.bn.running_var\", \"encoder.s1.b1.downsample.conv.weight\", \"encoder.s1.b1.downsample.bn.weight\", \"encoder.s1.b1.downsample.bn.bias\", \"encoder.s1.b1.downsample.bn.running_mean\", \"encoder.s1.b1.downsample.bn.running_var\", \"encoder.s1.b2.conv1.conv.weight\", \"encoder.s1.b2.conv1.bn.weight\", \"encoder.s1.b2.conv1.bn.bias\", \"encoder.s1.b2.conv1.bn.running_mean\", \"encoder.s1.b2.conv1.bn.running_var\", \"encoder.s1.b2.conv2.conv.weight\", \"encoder.s1.b2.conv2.bn.weight\", \"encoder.s1.b2.conv2.bn.bias\", \"encoder.s1.b2.conv2.bn.running_mean\", \"encoder.s1.b2.conv2.bn.running_var\", \"encoder.s1.b2.conv3.conv.weight\", \"encoder.s1.b2.conv3.bn.weight\", \"encoder.s1.b2.conv3.bn.bias\", \"encoder.s1.b2.conv3.bn.running_mean\", \"encoder.s1.b2.conv3.bn.running_var\", \"encoder.s2.b1.conv1.conv.weight\", \"encoder.s2.b1.conv1.bn.weight\", \"encoder.s2.b1.conv1.bn.bias\", \"encoder.s2.b1.conv1.bn.running_mean\", \"encoder.s2.b1.conv1.bn.running_var\", \"encoder.s2.b1.conv2.conv.weight\", \"encoder.s2.b1.conv2.bn.weight\", \"encoder.s2.b1.conv2.bn.bias\", \"encoder.s2.b1.conv2.bn.running_mean\", \"encoder.s2.b1.conv2.bn.running_var\", \"encoder.s2.b1.conv3.conv.weight\", \"encoder.s2.b1.conv3.bn.weight\", \"encoder.s2.b1.conv3.bn.bias\", \"encoder.s2.b1.conv3.bn.running_mean\", \"encoder.s2.b1.conv3.bn.running_var\", \"encoder.s2.b1.downsample.conv.weight\", \"encoder.s2.b1.downsample.bn.weight\", \"encoder.s2.b1.downsample.bn.bias\", \"encoder.s2.b1.downsample.bn.running_mean\", \"encoder.s2.b1.downsample.bn.running_var\", \"encoder.s2.b2.conv1.conv.weight\", \"encoder.s2.b2.conv1.bn.weight\", \"encoder.s2.b2.conv1.bn.bias\", \"encoder.s2.b2.conv1.bn.running_mean\", \"encoder.s2.b2.conv1.bn.running_var\", \"encoder.s2.b2.conv2.conv.weight\", \"encoder.s2.b2.conv2.bn.weight\", \"encoder.s2.b2.conv2.bn.bias\", \"encoder.s2.b2.conv2.bn.running_mean\", \"encoder.s2.b2.conv2.bn.running_var\", \"encoder.s2.b2.conv3.conv.weight\", \"encoder.s2.b2.conv3.bn.weight\", \"encoder.s2.b2.conv3.bn.bias\", \"encoder.s2.b2.conv3.bn.running_mean\", \"encoder.s2.b2.conv3.bn.running_var\", \"encoder.s2.b3.conv1.conv.weight\", \"encoder.s2.b3.conv1.bn.weight\", \"encoder.s2.b3.conv1.bn.bias\", \"encoder.s2.b3.conv1.bn.running_mean\", \"encoder.s2.b3.conv1.bn.running_var\", \"encoder.s2.b3.conv2.conv.weight\", \"encoder.s2.b3.conv2.bn.weight\", \"encoder.s2.b3.conv2.bn.bias\", \"encoder.s2.b3.conv2.bn.running_mean\", \"encoder.s2.b3.conv2.bn.running_var\", \"encoder.s2.b3.conv3.conv.weight\", \"encoder.s2.b3.conv3.bn.weight\", \"encoder.s2.b3.conv3.bn.bias\", \"encoder.s2.b3.conv3.bn.running_mean\", \"encoder.s2.b3.conv3.bn.running_var\", \"encoder.s2.b4.conv1.conv.weight\", \"encoder.s2.b4.conv1.bn.weight\", \"encoder.s2.b4.conv1.bn.bias\", \"encoder.s2.b4.conv1.bn.running_mean\", \"encoder.s2.b4.conv1.bn.running_var\", \"encoder.s2.b4.conv2.conv.weight\", \"encoder.s2.b4.conv2.bn.weight\", \"encoder.s2.b4.conv2.bn.bias\", \"encoder.s2.b4.conv2.bn.running_mean\", \"encoder.s2.b4.conv2.bn.running_var\", \"encoder.s2.b4.conv3.conv.weight\", \"encoder.s2.b4.conv3.bn.weight\", \"encoder.s2.b4.conv3.bn.bias\", \"encoder.s2.b4.conv3.bn.running_mean\", \"encoder.s2.b4.conv3.bn.running_var\", \"encoder.s2.b5.conv1.conv.weight\", \"encoder.s2.b5.conv1.bn.weight\", \"encoder.s2.b5.conv1.bn.bias\", \"encoder.s2.b5.conv1.bn.running_mean\", \"encoder.s2.b5.conv1.bn.running_var\", \"encoder.s2.b5.conv2.conv.weight\", \"encoder.s2.b5.conv2.bn.weight\", \"encoder.s2.b5.conv2.bn.bias\", \"encoder.s2.b5.conv2.bn.running_mean\", \"encoder.s2.b5.conv2.bn.running_var\", \"encoder.s2.b5.conv3.conv.weight\", \"encoder.s2.b5.conv3.bn.weight\", \"encoder.s2.b5.conv3.bn.bias\", \"encoder.s2.b5.conv3.bn.running_mean\", \"encoder.s2.b5.conv3.bn.running_var\", \"encoder.s3.b1.conv1.conv.weight\", \"encoder.s3.b1.conv1.bn.weight\", \"encoder.s3.b1.conv1.bn.bias\", \"encoder.s3.b1.conv1.bn.running_mean\", \"encoder.s3.b1.conv1.bn.running_var\", \"encoder.s3.b1.conv2.conv.weight\", \"encoder.s3.b1.conv2.bn.weight\", \"encoder.s3.b1.conv2.bn.bias\", \"encoder.s3.b1.conv2.bn.running_mean\", \"encoder.s3.b1.conv2.bn.running_var\", \"encoder.s3.b1.conv3.conv.weight\", \"encoder.s3.b1.conv3.bn.weight\", \"encoder.s3.b1.conv3.bn.bias\", \"encoder.s3.b1.conv3.bn.running_mean\", \"encoder.s3.b1.conv3.bn.running_var\", \"encoder.s3.b1.downsample.conv.weight\", \"encoder.s3.b1.downsample.bn.weight\", \"encoder.s3.b1.downsample.bn.bias\", \"encoder.s3.b1.downsample.bn.running_mean\", \"encoder.s3.b1.downsample.bn.running_var\", \"encoder.s3.b2.conv1.conv.weight\", \"encoder.s3.b2.conv1.bn.weight\", \"encoder.s3.b2.conv1.bn.bias\", \"encoder.s3.b2.conv1.bn.running_mean\", \"encoder.s3.b2.conv1.bn.running_var\", \"encoder.s3.b2.conv2.conv.weight\", \"encoder.s3.b2.conv2.bn.weight\", \"encoder.s3.b2.conv2.bn.bias\", \"encoder.s3.b2.conv2.bn.running_mean\", \"encoder.s3.b2.conv2.bn.running_var\", \"encoder.s3.b2.conv3.conv.weight\", \"encoder.s3.b2.conv3.bn.weight\", \"encoder.s3.b2.conv3.bn.bias\", \"encoder.s3.b2.conv3.bn.running_mean\", \"encoder.s3.b2.conv3.bn.running_var\", \"encoder.s3.b3.conv1.conv.weight\", \"encoder.s3.b3.conv1.bn.weight\", \"encoder.s3.b3.conv1.bn.bias\", \"encoder.s3.b3.conv1.bn.running_mean\", \"encoder.s3.b3.conv1.bn.running_var\", \"encoder.s3.b3.conv2.conv.weight\", \"encoder.s3.b3.conv2.bn.weight\", \"encoder.s3.b3.conv2.bn.bias\", \"encoder.s3.b3.conv2.bn.running_mean\", \"encoder.s3.b3.conv2.bn.running_var\", \"encoder.s3.b3.conv3.conv.weight\", \"encoder.s3.b3.conv3.bn.weight\", \"encoder.s3.b3.conv3.bn.bias\", \"encoder.s3.b3.conv3.bn.running_mean\", \"encoder.s3.b3.conv3.bn.running_var\", \"encoder.s3.b4.conv1.conv.weight\", \"encoder.s3.b4.conv1.bn.weight\", \"encoder.s3.b4.conv1.bn.bias\", \"encoder.s3.b4.conv1.bn.running_mean\", \"encoder.s3.b4.conv1.bn.running_var\", \"encoder.s3.b4.conv2.conv.weight\", \"encoder.s3.b4.conv2.bn.weight\", \"encoder.s3.b4.conv2.bn.bias\", \"encoder.s3.b4.conv2.bn.running_mean\", \"encoder.s3.b4.conv2.bn.running_var\", \"encoder.s3.b4.conv3.conv.weight\", \"encoder.s3.b4.conv3.bn.weight\", \"encoder.s3.b4.conv3.bn.bias\", \"encoder.s3.b4.conv3.bn.running_mean\", \"encoder.s3.b4.conv3.bn.running_var\", \"encoder.s3.b5.conv1.conv.weight\", \"encoder.s3.b5.conv1.bn.weight\", \"encoder.s3.b5.conv1.bn.bias\", \"encoder.s3.b5.conv1.bn.running_mean\", \"encoder.s3.b5.conv1.bn.running_var\", \"encoder.s3.b5.conv2.conv.weight\", \"encoder.s3.b5.conv2.bn.weight\", \"encoder.s3.b5.conv2.bn.bias\", \"encoder.s3.b5.conv2.bn.running_mean\", \"encoder.s3.b5.conv2.bn.running_var\", \"encoder.s3.b5.conv3.conv.weight\", \"encoder.s3.b5.conv3.bn.weight\", \"encoder.s3.b5.conv3.bn.bias\", \"encoder.s3.b5.conv3.bn.running_mean\", \"encoder.s3.b5.conv3.bn.running_var\", \"encoder.s3.b6.conv1.conv.weight\", \"encoder.s3.b6.conv1.bn.weight\", \"encoder.s3.b6.conv1.bn.bias\", \"encoder.s3.b6.conv1.bn.running_mean\", \"encoder.s3.b6.conv1.bn.running_var\", \"encoder.s3.b6.conv2.conv.weight\", \"encoder.s3.b6.conv2.bn.weight\", \"encoder.s3.b6.conv2.bn.bias\", \"encoder.s3.b6.conv2.bn.running_mean\", \"encoder.s3.b6.conv2.bn.running_var\", \"encoder.s3.b6.conv3.conv.weight\", \"encoder.s3.b6.conv3.bn.weight\", \"encoder.s3.b6.conv3.bn.bias\", \"encoder.s3.b6.conv3.bn.running_mean\", \"encoder.s3.b6.conv3.bn.running_var\", \"encoder.s3.b7.conv1.conv.weight\", \"encoder.s3.b7.conv1.bn.weight\", \"encoder.s3.b7.conv1.bn.bias\", \"encoder.s3.b7.conv1.bn.running_mean\", \"encoder.s3.b7.conv1.bn.running_var\", \"encoder.s3.b7.conv2.conv.weight\", \"encoder.s3.b7.conv2.bn.weight\", \"encoder.s3.b7.conv2.bn.bias\", \"encoder.s3.b7.conv2.bn.running_mean\", \"encoder.s3.b7.conv2.bn.running_var\", \"encoder.s3.b7.conv3.conv.weight\", \"encoder.s3.b7.conv3.bn.weight\", \"encoder.s3.b7.conv3.bn.bias\", \"encoder.s3.b7.conv3.bn.running_mean\", \"encoder.s3.b7.conv3.bn.running_var\", \"encoder.s3.b8.conv1.conv.weight\", \"encoder.s3.b8.conv1.bn.weight\", \"encoder.s3.b8.conv1.bn.bias\", \"encoder.s3.b8.conv1.bn.running_mean\", \"encoder.s3.b8.conv1.bn.running_var\", \"encoder.s3.b8.conv2.conv.weight\", \"encoder.s3.b8.conv2.bn.weight\", \"encoder.s3.b8.conv2.bn.bias\", \"encoder.s3.b8.conv2.bn.running_mean\", \"encoder.s3.b8.conv2.bn.running_var\", \"encoder.s3.b8.conv3.conv.weight\", \"encoder.s3.b8.conv3.bn.weight\", \"encoder.s3.b8.conv3.bn.bias\", \"encoder.s3.b8.conv3.bn.running_mean\", \"encoder.s3.b8.conv3.bn.running_var\", \"encoder.s3.b9.conv1.conv.weight\", \"encoder.s3.b9.conv1.bn.weight\", \"encoder.s3.b9.conv1.bn.bias\", \"encoder.s3.b9.conv1.bn.running_mean\", \"encoder.s3.b9.conv1.bn.running_var\", \"encoder.s3.b9.conv2.conv.weight\", \"encoder.s3.b9.conv2.bn.weight\", \"encoder.s3.b9.conv2.bn.bias\", \"encoder.s3.b9.conv2.bn.running_mean\", \"encoder.s3.b9.conv2.bn.running_var\", \"encoder.s3.b9.conv3.conv.weight\", \"encoder.s3.b9.conv3.bn.weight\", \"encoder.s3.b9.conv3.bn.bias\", \"encoder.s3.b9.conv3.bn.running_mean\", \"encoder.s3.b9.conv3.bn.running_var\", \"encoder.s3.b10.conv1.conv.weight\", \"encoder.s3.b10.conv1.bn.weight\", \"encoder.s3.b10.conv1.bn.bias\", \"encoder.s3.b10.conv1.bn.running_mean\", \"encoder.s3.b10.conv1.bn.running_var\", \"encoder.s3.b10.conv2.conv.weight\", \"encoder.s3.b10.conv2.bn.weight\", \"encoder.s3.b10.conv2.bn.bias\", \"encoder.s3.b10.conv2.bn.running_mean\", \"encoder.s3.b10.conv2.bn.running_var\", \"encoder.s3.b10.conv3.conv.weight\", \"encoder.s3.b10.conv3.bn.weight\", \"encoder.s3.b10.conv3.bn.bias\", \"encoder.s3.b10.conv3.bn.running_mean\", \"encoder.s3.b10.conv3.bn.running_var\", \"encoder.s3.b11.conv1.conv.weight\", \"encoder.s3.b11.conv1.bn.weight\", \"encoder.s3.b11.conv1.bn.bias\", \"encoder.s3.b11.conv1.bn.running_mean\", \"encoder.s3.b11.conv1.bn.running_var\", \"encoder.s3.b11.conv2.conv.weight\", \"encoder.s3.b11.conv2.bn.weight\", \"encoder.s3.b11.conv2.bn.bias\", \"encoder.s3.b11.conv2.bn.running_mean\", \"encoder.s3.b11.conv2.bn.running_var\", \"encoder.s3.b11.conv3.conv.weight\", \"encoder.s3.b11.conv3.bn.weight\", \"encoder.s3.b11.conv3.bn.bias\", \"encoder.s3.b11.conv3.bn.running_mean\", \"encoder.s3.b11.conv3.bn.running_var\", \"encoder.s3.b12.conv1.conv.weight\", \"encoder.s3.b12.conv1.bn.weight\", \"encoder.s3.b12.conv1.bn.bias\", \"encoder.s3.b12.conv1.bn.running_mean\", \"encoder.s3.b12.conv1.bn.running_var\", \"encoder.s3.b12.conv2.conv.weight\", \"encoder.s3.b12.conv2.bn.weight\", \"encoder.s3.b12.conv2.bn.bias\", \"encoder.s3.b12.conv2.bn.running_mean\", \"encoder.s3.b12.conv2.bn.running_var\", \"encoder.s3.b12.conv3.conv.weight\", \"encoder.s3.b12.conv3.bn.weight\", \"encoder.s3.b12.conv3.bn.bias\", \"encoder.s3.b12.conv3.bn.running_mean\", \"encoder.s3.b12.conv3.bn.running_var\", \"encoder.s3.b13.conv1.conv.weight\", \"encoder.s3.b13.conv1.bn.weight\", \"encoder.s3.b13.conv1.bn.bias\", \"encoder.s3.b13.conv1.bn.running_mean\", \"encoder.s3.b13.conv1.bn.running_var\", \"encoder.s3.b13.conv2.conv.weight\", \"encoder.s3.b13.conv2.bn.weight\", \"encoder.s3.b13.conv2.bn.bias\", \"encoder.s3.b13.conv2.bn.running_mean\", \"encoder.s3.b13.conv2.bn.running_var\", \"encoder.s3.b13.conv3.conv.weight\", \"encoder.s3.b13.conv3.bn.weight\", \"encoder.s3.b13.conv3.bn.bias\", \"encoder.s3.b13.conv3.bn.running_mean\", \"encoder.s3.b13.conv3.bn.running_var\", \"encoder.s3.b14.conv1.conv.weight\", \"encoder.s3.b14.conv1.bn.weight\", \"encoder.s3.b14.conv1.bn.bias\", \"encoder.s3.b14.conv1.bn.running_mean\", \"encoder.s3.b14.conv1.bn.running_var\", \"encoder.s3.b14.conv2.conv.weight\", \"encoder.s3.b14.conv2.bn.weight\", \"encoder.s3.b14.conv2.bn.bias\", \"encoder.s3.b14.conv2.bn.running_mean\", \"encoder.s3.b14.conv2.bn.running_var\", \"encoder.s3.b14.conv3.conv.weight\", \"encoder.s3.b14.conv3.bn.weight\", \"encoder.s3.b14.conv3.bn.bias\", \"encoder.s3.b14.conv3.bn.running_mean\", \"encoder.s3.b14.conv3.bn.running_var\", \"encoder.s4.b1.conv1.conv.weight\", \"encoder.s4.b1.conv1.bn.weight\", \"encoder.s4.b1.conv1.bn.bias\", \"encoder.s4.b1.conv1.bn.running_mean\", \"encoder.s4.b1.conv1.bn.running_var\", \"encoder.s4.b1.conv2.conv.weight\", \"encoder.s4.b1.conv2.bn.weight\", \"encoder.s4.b1.conv2.bn.bias\", \"encoder.s4.b1.conv2.bn.running_mean\", \"encoder.s4.b1.conv2.bn.running_var\", \"encoder.s4.b1.conv3.conv.weight\", \"encoder.s4.b1.conv3.bn.weight\", \"encoder.s4.b1.conv3.bn.bias\", \"encoder.s4.b1.conv3.bn.running_mean\", \"encoder.s4.b1.conv3.bn.running_var\", \"encoder.s4.b1.downsample.conv.weight\", \"encoder.s4.b1.downsample.bn.weight\", \"encoder.s4.b1.downsample.bn.bias\", \"encoder.s4.b1.downsample.bn.running_mean\", \"encoder.s4.b1.downsample.bn.running_var\", \"encoder.s4.b2.conv1.conv.weight\", \"encoder.s4.b2.conv1.bn.weight\", \"encoder.s4.b2.conv1.bn.bias\", \"encoder.s4.b2.conv1.bn.running_mean\", \"encoder.s4.b2.conv1.bn.running_var\", \"encoder.s4.b2.conv2.conv.weight\", \"encoder.s4.b2.conv2.bn.weight\", \"encoder.s4.b2.conv2.bn.bias\", \"encoder.s4.b2.conv2.bn.running_mean\", \"encoder.s4.b2.conv2.bn.running_var\", \"encoder.s4.b2.conv3.conv.weight\", \"encoder.s4.b2.conv3.bn.weight\", \"encoder.s4.b2.conv3.bn.bias\", \"encoder.s4.b2.conv3.bn.running_mean\", \"encoder.s4.b2.conv3.bn.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\". \n\tsize mismatch for decoder.blocks.x_0_0.conv1.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1920, 3, 3]).\n\tsize mismatch for decoder.blocks.x_0_1.conv1.0.weight: copying a param with shape torch.Size([128, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 736, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.0.weight: copying a param with shape torch.Size([128, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 800, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.0.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 240, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_0_2.conv1.0.weight: copying a param with shape torch.Size([64, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 368, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 400, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 320, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_0_3.conv1.0.weight: copying a param with shape torch.Size([32, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 192, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 176, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 144, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.0.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 112, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/notebooks/Testing/CV-131/MODEL-UnetPlusPlusresnet34CV-131_FINAL.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mUnetPlusPlus(\n\u001b[1;32m      6\u001b[0m     encoder_name\u001b[38;5;241m=\u001b[39mENCODER_NAME,           \u001b[38;5;66;03m# choose encoder, e.g. mobilenet_v2 or efficientnet-b7\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,                        \u001b[38;5;66;03m# model input channels (1 for gray-scale images, 3 for RGB, etc.)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,                            \u001b[38;5;66;03m# model output channels (number of classes in your dataset)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_image\u001b[39m(model, image, mask): \n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UnetPlusPlus:\n\tMissing key(s) in state_dict: \"encoder.stem.conv.weight\", \"encoder.stem.bn.weight\", \"encoder.stem.bn.bias\", \"encoder.stem.bn.running_mean\", \"encoder.stem.bn.running_var\", \"encoder.s1.b1.conv1.conv.weight\", \"encoder.s1.b1.conv1.bn.weight\", \"encoder.s1.b1.conv1.bn.bias\", \"encoder.s1.b1.conv1.bn.running_mean\", \"encoder.s1.b1.conv1.bn.running_var\", \"encoder.s1.b1.conv2.conv.weight\", \"encoder.s1.b1.conv2.bn.weight\", \"encoder.s1.b1.conv2.bn.bias\", \"encoder.s1.b1.conv2.bn.running_mean\", \"encoder.s1.b1.conv2.bn.running_var\", \"encoder.s1.b1.conv3.conv.weight\", \"encoder.s1.b1.conv3.bn.weight\", \"encoder.s1.b1.conv3.bn.bias\", \"encoder.s1.b1.conv3.bn.running_mean\", \"encoder.s1.b1.conv3.bn.running_var\", \"encoder.s1.b1.downsample.conv.weight\", \"encoder.s1.b1.downsample.bn.weight\", \"encoder.s1.b1.downsample.bn.bias\", \"encoder.s1.b1.downsample.bn.running_mean\", \"encoder.s1.b1.downsample.bn.running_var\", \"encoder.s1.b2.conv1.conv.weight\", \"encoder.s1.b2.conv1.bn.weight\", \"encoder.s1.b2.conv1.bn.bias\", \"encoder.s1.b2.conv1.bn.running_mean\", \"encoder.s1.b2.conv1.bn.running_var\", \"encoder.s1.b2.conv2.conv.weight\", \"encoder.s1.b2.conv2.bn.weight\", \"encoder.s1.b2.conv2.bn.bias\", \"encoder.s1.b2.conv2.bn.running_mean\", \"encoder.s1.b2.conv2.bn.running_var\", \"encoder.s1.b2.conv3.conv.weight\", \"encoder.s1.b2.conv3.bn.weight\", \"encoder.s1.b2.conv3.bn.bias\", \"encoder.s1.b2.conv3.bn.running_mean\", \"encoder.s1.b2.conv3.bn.running_var\", \"encoder.s2.b1.conv1.conv.weight\", \"encoder.s2.b1.conv1.bn.weight\", \"encoder.s2.b1.conv1.bn.bias\", \"encoder.s2.b1.conv1.bn.running_mean\", \"encoder.s2.b1.conv1.bn.running_var\", \"encoder.s2.b1.conv2.conv.weight\", \"encoder.s2.b1.conv2.bn.weight\", \"encoder.s2.b1.conv2.bn.bias\", \"encoder.s2.b1.conv2.bn.running_mean\", \"encoder.s2.b1.conv2.bn.running_var\", \"encoder.s2.b1.conv3.conv.weight\", \"encoder.s2.b1.conv3.bn.weight\", \"encoder.s2.b1.conv3.bn.bias\", \"encoder.s2.b1.conv3.bn.running_mean\", \"encoder.s2.b1.conv3.bn.running_var\", \"encoder.s2.b1.downsample.conv.weight\", \"encoder.s2.b1.downsample.bn.weight\", \"encoder.s2.b1.downsample.bn.bias\", \"encoder.s2.b1.downsample.bn.running_mean\", \"encoder.s2.b1.downsample.bn.running_var\", \"encoder.s2.b2.conv1.conv.weight\", \"encoder.s2.b2.conv1.bn.weight\", \"encoder.s2.b2.conv1.bn.bias\", \"encoder.s2.b2.conv1.bn.running_mean\", \"encoder.s2.b2.conv1.bn.running_var\", \"encoder.s2.b2.conv2.conv.weight\", \"encoder.s2.b2.conv2.bn.weight\", \"encoder.s2.b2.conv2.bn.bias\", \"encoder.s2.b2.conv2.bn.running_mean\", \"encoder.s2.b2.conv2.bn.running_var\", \"encoder.s2.b2.conv3.conv.weight\", \"encoder.s2.b2.conv3.bn.weight\", \"encoder.s2.b2.conv3.bn.bias\", \"encoder.s2.b2.conv3.bn.running_mean\", \"encoder.s2.b2.conv3.bn.running_var\", \"encoder.s2.b3.conv1.conv.weight\", \"encoder.s2.b3.conv1.bn.weight\", \"encoder.s2.b3.conv1.bn.bias\", \"encoder.s2.b3.conv1.bn.running_mean\", \"encoder.s2.b3.conv1.bn.running_var\", \"encoder.s2.b3.conv2.conv.weight\", \"encoder.s2.b3.conv2.bn.weight\", \"encoder.s2.b3.conv2.bn.bias\", \"encoder.s2.b3.conv2.bn.running_mean\", \"encoder.s2.b3.conv2.bn.running_var\", \"encoder.s2.b3.conv3.conv.weight\", \"encoder.s2.b3.conv3.bn.weight\", \"encoder.s2.b3.conv3.bn.bias\", \"encoder.s2.b3.conv3.bn.running_mean\", \"encoder.s2.b3.conv3.bn.running_var\", \"encoder.s2.b4.conv1.conv.weight\", \"encoder.s2.b4.conv1.bn.weight\", \"encoder.s2.b4.conv1.bn.bias\", \"encoder.s2.b4.conv1.bn.running_mean\", \"encoder.s2.b4.conv1.bn.running_var\", \"encoder.s2.b4.conv2.conv.weight\", \"encoder.s2.b4.conv2.bn.weight\", \"encoder.s2.b4.conv2.bn.bias\", \"encoder.s2.b4.conv2.bn.running_mean\", \"encoder.s2.b4.conv2.bn.running_var\", \"encoder.s2.b4.conv3.conv.weight\", \"encoder.s2.b4.conv3.bn.weight\", \"encoder.s2.b4.conv3.bn.bias\", \"encoder.s2.b4.conv3.bn.running_mean\", \"encoder.s2.b4.conv3.bn.running_var\", \"encoder.s2.b5.conv1.conv.weight\", \"encoder.s2.b5.conv1.bn.weight\", \"encoder.s2.b5.conv1.bn.bias\", \"encoder.s2.b5.conv1.bn.running_mean\", \"encoder.s2.b5.conv1.bn.running_var\", \"encoder.s2.b5.conv2.conv.weight\", \"encoder.s2.b5.conv2.bn.weight\", \"encoder.s2.b5.conv2.bn.bias\", \"encoder.s2.b5.conv2.bn.running_mean\", \"encoder.s2.b5.conv2.bn.running_var\", \"encoder.s2.b5.conv3.conv.weight\", \"encoder.s2.b5.conv3.bn.weight\", \"encoder.s2.b5.conv3.bn.bias\", \"encoder.s2.b5.conv3.bn.running_mean\", \"encoder.s2.b5.conv3.bn.running_var\", \"encoder.s3.b1.conv1.conv.weight\", \"encoder.s3.b1.conv1.bn.weight\", \"encoder.s3.b1.conv1.bn.bias\", \"encoder.s3.b1.conv1.bn.running_mean\", \"encoder.s3.b1.conv1.bn.running_var\", \"encoder.s3.b1.conv2.conv.weight\", \"encoder.s3.b1.conv2.bn.weight\", \"encoder.s3.b1.conv2.bn.bias\", \"encoder.s3.b1.conv2.bn.running_mean\", \"encoder.s3.b1.conv2.bn.running_var\", \"encoder.s3.b1.conv3.conv.weight\", \"encoder.s3.b1.conv3.bn.weight\", \"encoder.s3.b1.conv3.bn.bias\", \"encoder.s3.b1.conv3.bn.running_mean\", \"encoder.s3.b1.conv3.bn.running_var\", \"encoder.s3.b1.downsample.conv.weight\", \"encoder.s3.b1.downsample.bn.weight\", \"encoder.s3.b1.downsample.bn.bias\", \"encoder.s3.b1.downsample.bn.running_mean\", \"encoder.s3.b1.downsample.bn.running_var\", \"encoder.s3.b2.conv1.conv.weight\", \"encoder.s3.b2.conv1.bn.weight\", \"encoder.s3.b2.conv1.bn.bias\", \"encoder.s3.b2.conv1.bn.running_mean\", \"encoder.s3.b2.conv1.bn.running_var\", \"encoder.s3.b2.conv2.conv.weight\", \"encoder.s3.b2.conv2.bn.weight\", \"encoder.s3.b2.conv2.bn.bias\", \"encoder.s3.b2.conv2.bn.running_mean\", \"encoder.s3.b2.conv2.bn.running_var\", \"encoder.s3.b2.conv3.conv.weight\", \"encoder.s3.b2.conv3.bn.weight\", \"encoder.s3.b2.conv3.bn.bias\", \"encoder.s3.b2.conv3.bn.running_mean\", \"encoder.s3.b2.conv3.bn.running_var\", \"encoder.s3.b3.conv1.conv.weight\", \"encoder.s3.b3.conv1.bn.weight\", \"encoder.s3.b3.conv1.bn.bias\", \"encoder.s3.b3.conv1.bn.running_mean\", \"encoder.s3.b3.conv1.bn.running_var\", \"encoder.s3.b3.conv2.conv.weight\", \"encoder.s3.b3.conv2.bn.weight\", \"encoder.s3.b3.conv2.bn.bias\", \"encoder.s3.b3.conv2.bn.running_mean\", \"encoder.s3.b3.conv2.bn.running_var\", \"encoder.s3.b3.conv3.conv.weight\", \"encoder.s3.b3.conv3.bn.weight\", \"encoder.s3.b3.conv3.bn.bias\", \"encoder.s3.b3.conv3.bn.running_mean\", \"encoder.s3.b3.conv3.bn.running_var\", \"encoder.s3.b4.conv1.conv.weight\", \"encoder.s3.b4.conv1.bn.weight\", \"encoder.s3.b4.conv1.bn.bias\", \"encoder.s3.b4.conv1.bn.running_mean\", \"encoder.s3.b4.conv1.bn.running_var\", \"encoder.s3.b4.conv2.conv.weight\", \"encoder.s3.b4.conv2.bn.weight\", \"encoder.s3.b4.conv2.bn.bias\", \"encoder.s3.b4.conv2.bn.running_mean\", \"encoder.s3.b4.conv2.bn.running_var\", \"encoder.s3.b4.conv3.conv.weight\", \"encoder.s3.b4.conv3.bn.weight\", \"encoder.s3.b4.conv3.bn.bias\", \"encoder.s3.b4.conv3.bn.running_mean\", \"encoder.s3.b4.conv3.bn.running_var\", \"encoder.s3.b5.conv1.conv.weight\", \"encoder.s3.b5.conv1.bn.weight\", \"encoder.s3.b5.conv1.bn.bias\", \"encoder.s3.b5.conv1.bn.running_mean\", \"encoder.s3.b5.conv1.bn.running_var\", \"encoder.s3.b5.conv2.conv.weight\", \"encoder.s3.b5.conv2.bn.weight\", \"encoder.s3.b5.conv2.bn.bias\", \"encoder.s3.b5.conv2.bn.running_mean\", \"encoder.s3.b5.conv2.bn.running_var\", \"encoder.s3.b5.conv3.conv.weight\", \"encoder.s3.b5.conv3.bn.weight\", \"encoder.s3.b5.conv3.bn.bias\", \"encoder.s3.b5.conv3.bn.running_mean\", \"encoder.s3.b5.conv3.bn.running_var\", \"encoder.s3.b6.conv1.conv.weight\", \"encoder.s3.b6.conv1.bn.weight\", \"encoder.s3.b6.conv1.bn.bias\", \"encoder.s3.b6.conv1.bn.running_mean\", \"encoder.s3.b6.conv1.bn.running_var\", \"encoder.s3.b6.conv2.conv.weight\", \"encoder.s3.b6.conv2.bn.weight\", \"encoder.s3.b6.conv2.bn.bias\", \"encoder.s3.b6.conv2.bn.running_mean\", \"encoder.s3.b6.conv2.bn.running_var\", \"encoder.s3.b6.conv3.conv.weight\", \"encoder.s3.b6.conv3.bn.weight\", \"encoder.s3.b6.conv3.bn.bias\", \"encoder.s3.b6.conv3.bn.running_mean\", \"encoder.s3.b6.conv3.bn.running_var\", \"encoder.s3.b7.conv1.conv.weight\", \"encoder.s3.b7.conv1.bn.weight\", \"encoder.s3.b7.conv1.bn.bias\", \"encoder.s3.b7.conv1.bn.running_mean\", \"encoder.s3.b7.conv1.bn.running_var\", \"encoder.s3.b7.conv2.conv.weight\", \"encoder.s3.b7.conv2.bn.weight\", \"encoder.s3.b7.conv2.bn.bias\", \"encoder.s3.b7.conv2.bn.running_mean\", \"encoder.s3.b7.conv2.bn.running_var\", \"encoder.s3.b7.conv3.conv.weight\", \"encoder.s3.b7.conv3.bn.weight\", \"encoder.s3.b7.conv3.bn.bias\", \"encoder.s3.b7.conv3.bn.running_mean\", \"encoder.s3.b7.conv3.bn.running_var\", \"encoder.s3.b8.conv1.conv.weight\", \"encoder.s3.b8.conv1.bn.weight\", \"encoder.s3.b8.conv1.bn.bias\", \"encoder.s3.b8.conv1.bn.running_mean\", \"encoder.s3.b8.conv1.bn.running_var\", \"encoder.s3.b8.conv2.conv.weight\", \"encoder.s3.b8.conv2.bn.weight\", \"encoder.s3.b8.conv2.bn.bias\", \"encoder.s3.b8.conv2.bn.running_mean\", \"encoder.s3.b8.conv2.bn.running_var\", \"encoder.s3.b8.conv3.conv.weight\", \"encoder.s3.b8.conv3.bn.weight\", \"encoder.s3.b8.conv3.bn.bias\", \"encoder.s3.b8.conv3.bn.running_mean\", \"encoder.s3.b8.conv3.bn.running_var\", \"encoder.s3.b9.conv1.conv.weight\", \"encoder.s3.b9.conv1.bn.weight\", \"encoder.s3.b9.conv1.bn.bias\", \"encoder.s3.b9.conv1.bn.running_mean\", \"encoder.s3.b9.conv1.bn.running_var\", \"encoder.s3.b9.conv2.conv.weight\", \"encoder.s3.b9.conv2.bn.weight\", \"encoder.s3.b9.conv2.bn.bias\", \"encoder.s3.b9.conv2.bn.running_mean\", \"encoder.s3.b9.conv2.bn.running_var\", \"encoder.s3.b9.conv3.conv.weight\", \"encoder.s3.b9.conv3.bn.weight\", \"encoder.s3.b9.conv3.bn.bias\", \"encoder.s3.b9.conv3.bn.running_mean\", \"encoder.s3.b9.conv3.bn.running_var\", \"encoder.s3.b10.conv1.conv.weight\", \"encoder.s3.b10.conv1.bn.weight\", \"encoder.s3.b10.conv1.bn.bias\", \"encoder.s3.b10.conv1.bn.running_mean\", \"encoder.s3.b10.conv1.bn.running_var\", \"encoder.s3.b10.conv2.conv.weight\", \"encoder.s3.b10.conv2.bn.weight\", \"encoder.s3.b10.conv2.bn.bias\", \"encoder.s3.b10.conv2.bn.running_mean\", \"encoder.s3.b10.conv2.bn.running_var\", \"encoder.s3.b10.conv3.conv.weight\", \"encoder.s3.b10.conv3.bn.weight\", \"encoder.s3.b10.conv3.bn.bias\", \"encoder.s3.b10.conv3.bn.running_mean\", \"encoder.s3.b10.conv3.bn.running_var\", \"encoder.s3.b11.conv1.conv.weight\", \"encoder.s3.b11.conv1.bn.weight\", \"encoder.s3.b11.conv1.bn.bias\", \"encoder.s3.b11.conv1.bn.running_mean\", \"encoder.s3.b11.conv1.bn.running_var\", \"encoder.s3.b11.conv2.conv.weight\", \"encoder.s3.b11.conv2.bn.weight\", \"encoder.s3.b11.conv2.bn.bias\", \"encoder.s3.b11.conv2.bn.running_mean\", \"encoder.s3.b11.conv2.bn.running_var\", \"encoder.s3.b11.conv3.conv.weight\", \"encoder.s3.b11.conv3.bn.weight\", \"encoder.s3.b11.conv3.bn.bias\", \"encoder.s3.b11.conv3.bn.running_mean\", \"encoder.s3.b11.conv3.bn.running_var\", \"encoder.s3.b12.conv1.conv.weight\", \"encoder.s3.b12.conv1.bn.weight\", \"encoder.s3.b12.conv1.bn.bias\", \"encoder.s3.b12.conv1.bn.running_mean\", \"encoder.s3.b12.conv1.bn.running_var\", \"encoder.s3.b12.conv2.conv.weight\", \"encoder.s3.b12.conv2.bn.weight\", \"encoder.s3.b12.conv2.bn.bias\", \"encoder.s3.b12.conv2.bn.running_mean\", \"encoder.s3.b12.conv2.bn.running_var\", \"encoder.s3.b12.conv3.conv.weight\", \"encoder.s3.b12.conv3.bn.weight\", \"encoder.s3.b12.conv3.bn.bias\", \"encoder.s3.b12.conv3.bn.running_mean\", \"encoder.s3.b12.conv3.bn.running_var\", \"encoder.s3.b13.conv1.conv.weight\", \"encoder.s3.b13.conv1.bn.weight\", \"encoder.s3.b13.conv1.bn.bias\", \"encoder.s3.b13.conv1.bn.running_mean\", \"encoder.s3.b13.conv1.bn.running_var\", \"encoder.s3.b13.conv2.conv.weight\", \"encoder.s3.b13.conv2.bn.weight\", \"encoder.s3.b13.conv2.bn.bias\", \"encoder.s3.b13.conv2.bn.running_mean\", \"encoder.s3.b13.conv2.bn.running_var\", \"encoder.s3.b13.conv3.conv.weight\", \"encoder.s3.b13.conv3.bn.weight\", \"encoder.s3.b13.conv3.bn.bias\", \"encoder.s3.b13.conv3.bn.running_mean\", \"encoder.s3.b13.conv3.bn.running_var\", \"encoder.s3.b14.conv1.conv.weight\", \"encoder.s3.b14.conv1.bn.weight\", \"encoder.s3.b14.conv1.bn.bias\", \"encoder.s3.b14.conv1.bn.running_mean\", \"encoder.s3.b14.conv1.bn.running_var\", \"encoder.s3.b14.conv2.conv.weight\", \"encoder.s3.b14.conv2.bn.weight\", \"encoder.s3.b14.conv2.bn.bias\", \"encoder.s3.b14.conv2.bn.running_mean\", \"encoder.s3.b14.conv2.bn.running_var\", \"encoder.s3.b14.conv3.conv.weight\", \"encoder.s3.b14.conv3.bn.weight\", \"encoder.s3.b14.conv3.bn.bias\", \"encoder.s3.b14.conv3.bn.running_mean\", \"encoder.s3.b14.conv3.bn.running_var\", \"encoder.s4.b1.conv1.conv.weight\", \"encoder.s4.b1.conv1.bn.weight\", \"encoder.s4.b1.conv1.bn.bias\", \"encoder.s4.b1.conv1.bn.running_mean\", \"encoder.s4.b1.conv1.bn.running_var\", \"encoder.s4.b1.conv2.conv.weight\", \"encoder.s4.b1.conv2.bn.weight\", \"encoder.s4.b1.conv2.bn.bias\", \"encoder.s4.b1.conv2.bn.running_mean\", \"encoder.s4.b1.conv2.bn.running_var\", \"encoder.s4.b1.conv3.conv.weight\", \"encoder.s4.b1.conv3.bn.weight\", \"encoder.s4.b1.conv3.bn.bias\", \"encoder.s4.b1.conv3.bn.running_mean\", \"encoder.s4.b1.conv3.bn.running_var\", \"encoder.s4.b1.downsample.conv.weight\", \"encoder.s4.b1.downsample.bn.weight\", \"encoder.s4.b1.downsample.bn.bias\", \"encoder.s4.b1.downsample.bn.running_mean\", \"encoder.s4.b1.downsample.bn.running_var\", \"encoder.s4.b2.conv1.conv.weight\", \"encoder.s4.b2.conv1.bn.weight\", \"encoder.s4.b2.conv1.bn.bias\", \"encoder.s4.b2.conv1.bn.running_mean\", \"encoder.s4.b2.conv1.bn.running_var\", \"encoder.s4.b2.conv2.conv.weight\", \"encoder.s4.b2.conv2.bn.weight\", \"encoder.s4.b2.conv2.bn.bias\", \"encoder.s4.b2.conv2.bn.running_mean\", \"encoder.s4.b2.conv2.bn.running_var\", \"encoder.s4.b2.conv3.conv.weight\", \"encoder.s4.b2.conv3.bn.weight\", \"encoder.s4.b2.conv3.bn.bias\", \"encoder.s4.b2.conv3.bn.running_mean\", \"encoder.s4.b2.conv3.bn.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\". \n\tsize mismatch for decoder.blocks.x_0_0.conv1.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1920, 3, 3]).\n\tsize mismatch for decoder.blocks.x_0_1.conv1.0.weight: copying a param with shape torch.Size([128, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 736, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.0.weight: copying a param with shape torch.Size([128, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 800, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.0.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 240, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_0_2.conv1.0.weight: copying a param with shape torch.Size([64, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 368, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 400, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 320, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_0_3.conv1.0.weight: copying a param with shape torch.Size([32, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 192, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 176, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 144, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.0.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 112, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32])."
     ]
    }
   ],
   "source": [
    "image_path = \"/notebooks/image_segmentation/network/image_data/train/images/patient_116.png\"\n",
    "mask_path = \"/notebooks/image_segmentation/network/image_data/train/masks/segmentation_116.png\" \n",
    "model_path = \"/notebooks/Testing/CV-131/MODEL-UnetPlusPlusresnet34CV-131_FINAL.pth\" \n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER_NAME,           # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    in_channels=3,                        # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                            # model output channels (number of classes in your dataset)\n",
    ")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "def predict_image(model, image, mask): \n",
    "\n",
    "    if type(image) == str: \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path)\n",
    "    \n",
    "        image, mask = convert_to_torch(image, mask)\n",
    "    \n",
    "    out = model(image.unsqueeze(0)) \n",
    "\n",
    "    segment_map = torch.sigmoid(out).squeeze(0).detach()\n",
    "    segment_map = (segment_map > 0.5) * 1\n",
    "    \n",
    "    plot_image_and_mask(image, mask)\n",
    "    plot_image_and_mask(image, segment_map)\n",
    "    \n",
    "#predict_image(model, image_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37722568-cb5a-48b7-8371-dbe22f52cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "\n",
    "for image, mask in DataLoader(valDataset, batch_size=1, shuffle=False, num_workers=0): \n",
    "    predict_image(model, image.squeeze(0), mask.squeeze(0))\n",
    "    print(\"-----------------------\")\n",
    "    count += 1\n",
    "    if count == 50:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
