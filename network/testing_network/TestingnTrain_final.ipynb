{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a86ac80-c99a-4e43-80ed-e04f4857d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation_models_pytorch\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (4.64.1)\n",
      "Collecting timm==0.9.2\n",
      "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (9.2.0)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (0.13.1+cu116)\n",
      "Collecting efficientnet-pytorch==0.7.1\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pretrainedmodels==0.7.4\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12.1+cu116)\n",
      "Collecting munch\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (4.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.8)\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=6b1d98847b3bb74a8906fe5f08bb49c5b0e91c6b995f1dd9506d6746995a89c9\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/16/f1/5369d23a06852d5f083d23a1addf0904575f1296f71b412ac8\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=f91f0d397e73d1a01db90df5996b8e2f488980bd3bda5f09486db0fe28889e28\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/9b/f5/9ccf39b50bc437986145107e2ced70a6fab622cf23e4795aa5\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\n",
      "Installing collected packages: safetensors, munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n",
      "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.4.0 segmentation_models_pytorch-0.3.3 timm-0.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting neptune\n",
      "  Downloading neptune-1.8.3-py3-none-any.whl (473 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.6/473.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (1.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from neptune) (1.14.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (8.1.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from neptune) (1.5.0)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.9/dist-packages (from neptune) (3.1.30)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.9/dist-packages (from neptune) (9.2.0)\n",
      "Collecting boto3>=1.28.0\n",
      "  Downloading boto3-1.29.2-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting bravado<12.0.0,>=11.0.0\n",
      "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from neptune) (5.9.4)\n",
      "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (2.28.2)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (0.57.0)\n",
      "Requirement already satisfied: future>=0.17.1 in /usr/lib/python3/dist-packages (from neptune) (0.18.2)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from neptune) (3.2.2)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from neptune) (1.26.14)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from neptune) (23.0)\n",
      "Collecting swagger-spec-validator>=2.7.4\n",
      "  Downloading swagger_spec_validator-3.0.3-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3>=1.28.0->neptune) (1.0.1)\n",
      "Collecting s3transfer<0.8.0,>=0.7.0\n",
      "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting botocore<1.33.0,>=1.32.2\n",
      "  Downloading botocore-1.32.2-py3-none-any.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting monotonic\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting bravado-core>=5.16.1\n",
      "  Downloading bravado_core-6.1.0-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (2.8.2)\n",
      "Collecting simplejson\n",
      "  Downloading simplejson-3.19.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.0.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (5.4.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=2.0.8->neptune) (4.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.20.0->neptune) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.20.0->neptune) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20.0->neptune) (2.1.1)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/dist-packages (from swagger-spec-validator>=2.7.4->neptune) (4.17.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas->neptune) (1.23.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neptune) (2022.7.1)\n",
      "Collecting jsonref\n",
      "  Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (18.2.0)\n",
      "Collecting rfc3987\n",
      "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
      "Collecting jsonpointer>1.13\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting webcolors>=1.11\n",
      "  Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Collecting isoduration\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Collecting uri-template\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Collecting rfc3339-validator\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting fqdn\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting arrow>=0.15.0\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting types-python-dateutil>=2.8.10\n",
      "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
      "Installing collected packages: types-python-dateutil, rfc3987, monotonic, webcolors, uri-template, simplejson, rfc3339-validator, PyJWT, jsonref, jsonpointer, fqdn, swagger-spec-validator, botocore, arrow, s3transfer, isoduration, boto3, bravado-core, bravado, neptune\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.90\n",
      "    Uninstalling botocore-1.27.90:\n",
      "      Successfully uninstalled botocore-1.27.90\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.6.0\n",
      "    Uninstalling s3transfer-0.6.0:\n",
      "      Successfully uninstalled s3transfer-0.6.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.24.90\n",
      "    Uninstalling boto3-1.24.90:\n",
      "      Successfully uninstalled boto3-1.24.90\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.25.91 requires botocore==1.27.90, but you have botocore 1.32.2 which is incompatible.\n",
      "awscli 1.25.91 requires s3transfer<0.7.0,>=0.6.0, but you have s3transfer 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyJWT-2.8.0 arrow-1.3.0 boto3-1.29.2 botocore-1.32.2 bravado-11.0.3 bravado-core-6.1.0 fqdn-1.5.1 isoduration-20.11.0 jsonpointer-2.4 jsonref-1.1.0 monotonic-1.6 neptune-1.8.3 rfc3339-validator-0.1.4 rfc3987-1.3.8 s3transfer-0.7.0 simplejson-3.19.2 swagger-spec-validator-3.0.3 types-python-dateutil-2.8.19.14 uri-template-1.3.0 webcolors-1.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchmetrics\n",
      "  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.12.1+cu116)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.23.4)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.4.0)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting albumentations\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.23.4)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.9.2)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2.25.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.1.23.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.1 opencv-python-headless-4.8.1.78 qudida-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install segmentation_models_pytorch \n",
    "!pip install neptune\n",
    "!pip install torchmetrics\n",
    "!pip install albumentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85aa78b5-8605-4b7e-ad76-c342f86b5505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import segmentation_models_pytorch as smp\n",
    "import neptune\n",
    "from neptune.types import File\n",
    "\n",
    "from torchmetrics.functional.classification import dice as calc_dice_score\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5802c0f-a809-488a-9f58-eb29977ee095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_axis(shape):\n",
    "    # Three dimensional\n",
    "    if len(shape) == 5 : return [2,3,4]\n",
    "\n",
    "    # Two dimensional\n",
    "    elif len(shape) == 4 : return [2,3]\n",
    "    \n",
    "    # Exception - Unknown\n",
    "    else : raise ValueError('Metric: Shape of tensor is neither 2D or 3D.')\n",
    "\n",
    "class AsymmetricFocalLoss(nn.Module):\n",
    "    \"\"\"For Imbalanced datasets\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.25\n",
    "    gamma : float, optional\n",
    "        Focal Tversky loss' focal parameter controls degree of down-weighting of easy examples, by default 2.0\n",
    "    epsilon : float, optional\n",
    "        clip values to prevent division by zero error\n",
    "    \"\"\"\n",
    "    def __init__(self, delta=0.7, gamma=2., epsilon=1e-07):\n",
    "        super(AsymmetricFocalLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred_raw, y_true):\n",
    "        # Apply sigmoid function to raw output\n",
    "        y_pred = torch.sigmoid(y_pred_raw)\n",
    "        \n",
    "        # Rest of the code remains the same\n",
    "        y_pred = torch.clamp(y_pred, self.epsilon, 1. - self.epsilon)\n",
    "        cross_entropy = -y_true * torch.log(y_pred) - (1 - y_true) * torch.log(1 - y_pred)\n",
    "        \n",
    "        # Calculate losses separately for each class, only suppressing background class\n",
    "        back_ce = torch.pow(1 - y_pred, self.gamma) * cross_entropy\n",
    "        back_ce =  (1 - self.delta) * back_ce\n",
    "\n",
    "        fore_ce = cross_entropy\n",
    "        fore_ce = self.delta * fore_ce\n",
    "\n",
    "        loss = torch.mean(torch.sum(torch.stack([back_ce, fore_ce], axis=-1), axis=-1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AsymmetricFocalTverskyLoss(nn.Module):\n",
    "    \"\"\"This is the implementation for binary segmentation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float, optional\n",
    "        controls weight given to false positive and false negatives, by default 0.7\n",
    "    gamma : float, optional\n",
    "        focal parameter controls degree of down-weighting of easy examples, by default 0.75\n",
    "    smooth : float, optional\n",
    "        smooithing constant to prevent division by 0 errors, by default 0.000001\n",
    "    epsilon : float, optional\n",
    "        clip values to prevent division by zero error\n",
    "    \"\"\"\n",
    "    def __init__(self, delta=0.7, gamma=0.75, epsilon=1e-07):\n",
    "        super(AsymmetricFocalTverskyLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Clip values to prevent division by zero error\n",
    "        y_pred = torch.clamp(y_pred, self.epsilon, 1. - self.epsilon)\n",
    "        axis = identify_axis(y_true.size())\n",
    "\n",
    "        # Calculate true positives (tp), false negatives (fn) and false positives (fp)     \n",
    "        tp = torch.sum(y_true * y_pred, axis=axis)\n",
    "        fn = torch.sum(y_true * (1-y_pred), axis=axis)\n",
    "        fp = torch.sum((1-y_true) * y_pred, axis=axis)\n",
    "        dice_class = (tp + self.epsilon)/(tp + self.delta*fn + (1-self.delta)*fp + self.epsilon)\n",
    "\n",
    "        # Calculate losses separately for each class, only enhancing foreground class\n",
    "        back_dice = (1-dice_class[:,0]) \n",
    "        fore_dice = (1-dice_class[:,0]) * torch.pow(1-dice_class[:,0], -self.gamma)\n",
    "\n",
    "        # Average class scores\n",
    "        loss = torch.mean(torch.stack([back_dice,fore_dice], axis=-1))\n",
    "        return loss\n",
    "\n",
    "class AsymmetricUnifiedFocalLoss(nn.Module):\n",
    "    \"\"\"The Unified Focal loss is a new compound loss function that unifies Dice-based and cross entropy-based loss functions into a single framework.\n",
    "    Parameters\n",
    "    ----------\n",
    "    weight : float, optional\n",
    "        represents lambda parameter and controls weight given to asymmetric Focal Tversky loss and asymmetric Focal loss, by default 0.5\n",
    "    delta : float, optional\n",
    "        controls weight given to each class, by default 0.6\n",
    "    gamma : float, optional\n",
    "        focal parameter controls the degree of background suppression and foreground enhancement, by default 0.5\n",
    "    epsilon : float, optional\n",
    "        clip values to prevent division by zero error\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=0.5, delta=0.7, gamma=0.5):\n",
    "        super(AsymmetricUnifiedFocalLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.delta = delta\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "      # Obtain Asymmetric Focal Tversky loss\n",
    "      asymmetric_ftl = AsymmetricFocalTverskyLoss(delta=self.delta, gamma=self.gamma)(y_pred, y_true)\n",
    "\n",
    "      # Obtain Asymmetric Focal loss\n",
    "      asymmetric_fl = AsymmetricFocalLoss(delta=self.delta, gamma=self.gamma)(y_pred, y_true)\n",
    "\n",
    "      # Return weighted sum of Asymmetrical Focal loss and Asymmetric Focal Tversky loss\n",
    "      if self.weight is not None:\n",
    "        return (self.weight * asymmetric_ftl) + ((1-self.weight) * asymmetric_fl)  \n",
    "      else:\n",
    "        return asymmetric_ftl + asymmetric_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef354a13-0142-428f-9166-95f9a894ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7dd68c-6f39-4609-9e1a-75d9314bc9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5731/2955291135.py:15: NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/Kernel-bois/computer-vision/e/CV-265\n"
     ]
    }
   ],
   "source": [
    "# Define a custom dataset class\n",
    "# Training params\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.000045\n",
    "\n",
    "# Model params\n",
    "ENCODER_NAME = \"resnet34\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "\n",
    "with open(\"/notebooks/NEPTUNE_API_TOKEN.txt\", \"r\") as file:\n",
    "    # Read the entire content of the file into a string\n",
    "    token = file.read()\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"Kernel-bois/computer-vision\",\n",
    "    api_token=token,\n",
    ")\n",
    "run_id = run[\"sys/id\"].fetch()\n",
    "\n",
    "# Create the model\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER_NAME,           # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=ENCODER_WEIGHTS,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                        # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                            # model output channels (number of classes in your dataset)\n",
    "    )\n",
    "\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', threshold = 0.001, patience = 5)\n",
    "\n",
    "run_name = \"MODEL-\" + model.__class__.__name__ + ENCODER_NAME + str(run_id)\n",
    "\n",
    "save_path = str(run_id) + \"/\"\n",
    "os.makedirs(save_path)\n",
    "\n",
    "# Proper directories\n",
    "TRAIN_DATA_DIR = '/notebooks/image_segmentation/network/image_data_all3/train'\n",
    "VAL_DATA_DIR = '/notebooks/image_segmentation/network/image_data_all3/val'\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "# criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=False)  # Binary dice Loss for binary segmentation\n",
    "# criterion = smp.losses.SoftBCEWithLogitsLoss()  # Binary dice Loss for binary segmentation\n",
    "criterion = AsymmetricUnifiedFocalLoss()  # Binary dice Loss for binary segmentation\n",
    "calc_iou = BinaryJaccardIndex().to(device)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"MODEL\": model.__class__.__name__,\n",
    "    \"BACKBONE\": ENCODER_NAME,\n",
    "    \"ENCODER_WEIGHTS\": ENCODER_WEIGHTS,\n",
    "    \"BATCH_SIZE\": str(BATCH_SIZE),\n",
    "    \"EPOCHS\": str(EPOCHS),\n",
    "    \"CRITERION\": criterion.__class__.__name__,\n",
    "    \"OPTIMIZER\": optimizer.__class__.__name__,\n",
    "    \"LEARNRATE\": str(LEARNING_RATE),\n",
    "    \"MODEL_NAME\": run_name,\n",
    "}\n",
    "\n",
    "run[\"params\"] = params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea045fa-5b8e-4173-ad61-1d6c1cfc52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform = None, target_size = (992, 416)):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "\n",
    "        self.image_folder = os.path.join(root_dir, 'images')\n",
    "        self.mask_folder = os.path.join(root_dir, 'masks')\n",
    "\n",
    "        self.images = os.listdir(self.image_folder)\n",
    "        self.masks = os.listdir(self.mask_folder)\n",
    "        \n",
    "        assert len(self.images) == len(self.masks), \"Number of images and masks should be the same.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_folder, self.images[idx])\n",
    "        if \"patient\" in self.images[idx]:\n",
    "            mask_path = os.path.join(self.mask_folder, \"segmentation_\" + self.images[idx][-7:])\n",
    "        else:\n",
    "            mask_path = os.path.join(self.mask_folder, \"target_seg_\" + self.images[idx][-7:])\n",
    "        \n",
    "        # Load images\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "\n",
    "        # Convert to tensors \n",
    "        tensor_image = torch.from_numpy(image)\n",
    "        tensor_image = tensor_image.permute(2, 0, 1)\n",
    "\n",
    "        tensor_mask = torch.from_numpy(mask)\n",
    "        tensor_mask = tensor_mask.permute(2, 0, 1) / 255\n",
    "        tensor_mask = tensor_mask[2:, :, :]\n",
    "        \n",
    "        # add padding\n",
    "        pad_height = max(self.target_size[0] - tensor_image.size(1), 0)\n",
    "        pad_width = max(self.target_size[1] - tensor_image.size(2), 0)\n",
    "\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        padded_image = transforms.functional.pad(tensor_image, (pad_left, pad_bottom, pad_right, pad_top), fill=255)\n",
    "        padded_mask = transforms.functional.pad(tensor_mask, (pad_left, pad_bottom, pad_right, pad_top), fill=0)\n",
    "\n",
    "        return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d066e50c-8736-49c2-a1b2-cafd60dcb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# Set up dataset and dataloader\n",
    "transform = A.Compose([])\n",
    "#transform = A.Compose([A.OneOf([A.GaussNoise(p = 1), A.RandomGamma(p = 1), A.Sharpen(p=1), A.Resize(width = np.random.randint(200, 416), height = np.random.randint(200,992), p = 1) ],p=0.7), A.OneOf([A.GaussNoise(p = 1), A.RandomGamma(p = 1), A.Sharpen(p=1),A.Resize(width = np.random.randint(200, 416), height = np.random.randint(200,992), p = 1) ],p=0.3)])\n",
    "#\n",
    "#transform = A.Compose([A.GaussNoise(p = 0.2), A.RandomGamma(p = 0.2), A.Sharpen(p=0.2),\n",
    "#                       A.Resize(width = np.random.randint(200, 416), height = np.random.randint(200,992), p = 0.2)])\n",
    "\"\"\" \n",
    "\n",
    " A.Compose([A.HorizontalFlip(p=0.5), A.OneOf([A.GaussNoise(p = 1), A.RandomGamma(p = 1), A.Sharpen(p=1), \n",
    "                       A.Resize(width = np.random.randint(200, 416), height = np.random.randint(200,992), p = 1)],p=0.5)])\n",
    "\"\"\"\n",
    "# ALL Transforms\n",
    "# A.CLAHE(p=0.2)\n",
    "# A.HorizontalFlip(p=0.5),\n",
    "# A.RandomGamma(p=0.2)\n",
    "# A.GridDistortion(p=0.2)\n",
    "# A.RandomBrightnessContrast(p=0.2)\n",
    "# A.Resize(width = np.random.randint(200, 416), height = np.random.randint(200,992), p = 0.2)\n",
    "# A.OneOf([ ],p=0.9) for more \n",
    "# A.Sharpen(p=0.2)\n",
    "# A.Blur(p=0.2)\n",
    "# A.RandomCrop(height = 200, width=200, p=0.2)\n",
    "# GaussNoise(p = 0.2)\n",
    "\n",
    "trainDataset = SegmentationDataset(root_dir=TRAIN_DATA_DIR, transform=transform)\n",
    "valDataset = SegmentationDataset(root_dir=VAL_DATA_DIR)\n",
    "\n",
    "train_loader = DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(valDataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e995c-aab0-44fd-ab12-af8d056ae0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/4210636419.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_masks_int = torch.tensor(val_masks, dtype=torch.int8)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.9927887320518494, Validation Loss: 0.9802963733673096\n",
      "IOU: 0.01371900737285614, Dice Score: 0.026982637122273445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Train Loss: 0.9901798367500305, Validation Loss: 0.9748908877372742\n",
      "IOU: 0.02892202138900757, Dice Score: 0.055961623787879944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Train Loss: 0.988048255443573, Validation Loss: 0.9761552214622498\n",
      "IOU: 0.05618658289313316, Dice Score: 0.10538797825574875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Train Loss: 0.9858904480934143, Validation Loss: 0.9624328017234802\n",
      "IOU: 0.10557689517736435, Dice Score: 0.18986183404922485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Train Loss: 0.9828876852989197, Validation Loss: 0.9575397372245789\n",
      "IOU: 0.14457498490810394, Dice Score: 0.25073641538619995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Train Loss: 0.9793909788131714, Validation Loss: 0.9497098922729492\n",
      "IOU: 0.12249438464641571, Dice Score: 0.2161562591791153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Train Loss: 0.9741501212120056, Validation Loss: 0.9348689913749695\n",
      "IOU: 0.20168690383434296, Dice Score: 0.33247584104537964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Train Loss: 0.9689496755599976, Validation Loss: 0.9216614365577698\n",
      "IOU: 0.1912747472524643, Dice Score: 0.31848862767219543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]          /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Train Loss: 0.960737407207489, Validation Loss: 0.8958742022514343\n",
      "IOU: 0.4160194396972656, Dice Score: 0.5826720595359802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 0.9480918049812317, Validation Loss: 0.8724563717842102\n",
      "IOU: 0.45275115966796875, Dice Score: 0.6161086559295654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Train Loss: 0.935570240020752, Validation Loss: 0.8647222518920898\n",
      "IOU: 0.17224180698394775, Dice Score: 0.2906143069267273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Train Loss: 0.9098482728004456, Validation Loss: 0.8019484877586365\n",
      "IOU: 0.5125585794448853, Dice Score: 0.6714134812355042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Train Loss: 0.8810474872589111, Validation Loss: 0.7373595833778381\n",
      "IOU: 0.4305485785007477, Dice Score: 0.599831223487854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Train Loss: 0.834848165512085, Validation Loss: 0.6705369353294373\n",
      "IOU: 0.46636712551116943, Dice Score: 0.6334206461906433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Train Loss: 0.787290632724762, Validation Loss: 0.7360660433769226\n",
      "IOU: 0.2146247774362564, Dice Score: 0.3404843211174011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Train Loss: 0.7204568982124329, Validation Loss: 0.5025706887245178\n",
      "IOU: 0.5841635465621948, Dice Score: 0.7342085242271423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Train Loss: 0.6366013288497925, Validation Loss: 0.49566027522087097\n",
      "IOU: 0.4676094055175781, Dice Score: 0.6223363876342773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Train Loss: 0.5652099847793579, Validation Loss: 0.39448773860931396\n",
      "IOU: 0.5829125642776489, Dice Score: 0.7272955179214478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Train Loss: 0.49485230445861816, Validation Loss: 0.3484908640384674\n",
      "IOU: 0.5897874236106873, Dice Score: 0.7325799465179443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Train Loss: 0.4393582046031952, Validation Loss: 0.3337964117527008\n",
      "IOU: 0.6017965078353882, Dice Score: 0.7406086325645447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Train Loss: 0.3905489146709442, Validation Loss: 0.2907753586769104\n",
      "IOU: 0.6320322751998901, Dice Score: 0.770823061466217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Train Loss: 0.3762131631374359, Validation Loss: 0.2845476269721985\n",
      "IOU: 0.615077018737793, Dice Score: 0.7542890310287476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Train Loss: 0.3595917224884033, Validation Loss: 0.23303738236427307\n",
      "IOU: 0.6740050911903381, Dice Score: 0.8027042746543884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Train Loss: 0.30445563793182373, Validation Loss: 0.22547802329063416\n",
      "IOU: 0.6762659549713135, Dice Score: 0.8050290942192078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Train Loss: 0.2860942482948303, Validation Loss: 0.39270612597465515\n",
      "IOU: 0.469266414642334, Dice Score: 0.6222317218780518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Train Loss: 0.27139729261398315, Validation Loss: 0.2895395755767822\n",
      "IOU: 0.5811893939971924, Dice Score: 0.7281773090362549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Train Loss: 0.28564658761024475, Validation Loss: 0.23072881996631622\n",
      "IOU: 0.6532652378082275, Dice Score: 0.7866107821464539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Train Loss: 0.245477557182312, Validation Loss: 0.2374807894229889\n",
      "IOU: 0.6424047946929932, Dice Score: 0.7781686186790466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Train Loss: 0.23535723984241486, Validation Loss: 0.21684755384922028\n",
      "IOU: 0.6694793701171875, Dice Score: 0.7967092990875244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Train Loss: 0.23030538856983185, Validation Loss: 0.21404482424259186\n",
      "IOU: 0.6696136593818665, Dice Score: 0.7984399795532227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Train Loss: 0.22832220792770386, Validation Loss: 0.20061159133911133\n",
      "IOU: 0.6849263310432434, Dice Score: 0.8101657629013062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Train Loss: 0.21331787109375, Validation Loss: 0.22272950410842896\n",
      "IOU: 0.6522389054298401, Dice Score: 0.7865728735923767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Train Loss: 0.2037600725889206, Validation Loss: 0.2118222713470459\n",
      "IOU: 0.6668439507484436, Dice Score: 0.7972186803817749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Train Loss: 0.23204964399337769, Validation Loss: 0.20859995484352112\n",
      "IOU: 0.6724777817726135, Dice Score: 0.7994716167449951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Train Loss: 0.19261759519577026, Validation Loss: 0.2080453485250473\n",
      "IOU: 0.6729398369789124, Dice Score: 0.7996243834495544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Train Loss: 0.14927054941654205, Validation Loss: 0.21430836617946625\n",
      "IOU: 0.661419689655304, Dice Score: 0.7929033637046814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Validation:   0%|          | 0/11 [00:00<?, ?it/s]           /tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Train Loss: 0.16637198626995087, Validation Loss: 0.18912415206432343\n",
      "IOU: 0.6964561343193054, Dice Score: 0.8174368143081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100:   0%|          | 0/76 [00:00<?, ?it/s]/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "/tmp/ipykernel_5731/3131361502.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)\n",
      "Epoch 38/100:  54%|█████▍    | 41/76 [00:24<00:19,  1.75it/s]"
     ]
    }
   ],
   "source": [
    "# Train Loop\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = torch.tensor(0.0)\n",
    "    model.train()\n",
    "\n",
    "    # Use tqdm to add a progress bar\n",
    "    for images, masks in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{EPOCHS}', leave=False):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # outputs = torch.argmax(outputs, dim=1).unsqueeze(1).float()\n",
    "\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss += loss.detach().cpu()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    run[\"loss/train_loss\"].log(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = torch.tensor(0.0)\n",
    "    iou = torch.tensor(0.0)\n",
    "    dice_score = torch.tensor(0.0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_masks in tqdm(val_loader, desc=f'Validation', leave=False):\n",
    "            val_images, val_masks = val_images.to(device), val_masks.to(device)\n",
    "\n",
    "            model_outputs = model(val_images)\n",
    "\n",
    "            val_loss += criterion(model_outputs, val_masks).cpu()\n",
    "\n",
    "            val_masks_int = torch.tensor(val_masks, dtype=torch.int8)\n",
    "            dice_score += calc_dice_score(torch.sigmoid(model_outputs), val_masks_int, ignore_index=0).cpu()\n",
    "\n",
    "            iou += calc_iou(model_outputs, val_masks_int).cpu()\n",
    "\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    iou /= len(val_loader)\n",
    "    dice_score /= len(val_loader)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if torch.isnan(iou):\n",
    "        iou = torch.tensor(0.0)\n",
    "\n",
    "    run[\"loss/val_loss\"].log(val_loss)\n",
    "    run[\"val/iou\"].log(iou)\n",
    "    run[\"val/dice_score\"].log(dice_score)\n",
    "\n",
    "    torch.save(model.state_dict(), save_path + run_name + \"_EPOCH_\" + str(epoch) + '.pth')\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{EPOCHS}], Train Loss: {train_loss}, Validation Loss: {val_loss}\\n\"\n",
    "          f\"IOU: {iou}, Dice Score: {dice_score}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), save_path + run_name + \"_FINAL\" + '.pth')\n",
    "run[f\"network/network_weights\"].upload(File(run_name + '.pth'))\n",
    "\n",
    "run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d46fd-21e8-4ef3-b478-ba64763860fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17303f4-c66d-408f-ab68-5dd53c365af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Declare an augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.RandomCrop(height = 200, width=200, p=1)\n",
    "])\n",
    "\n",
    "image_path = \"/notebooks/image_segmentation/network/image_data/train/images/patient_116.png\"\n",
    "mask_path = \"/notebooks/image_segmentation/network/image_data/train/masks/segmentation_116.png\" \n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "mask = cv2.imread(mask_path)\n",
    "\n",
    "transformed = transform(image=image, mask=mask)\n",
    "transformed_image = transformed['image']\n",
    "transformed_mask = transformed['mask']\n",
    "\n",
    "image_torch, mask_torch = convert_to_torch(image, mask)\n",
    "plot_image_and_mask(image_torch, mask_torch)\n",
    "    \n",
    "image_torch, mask_torch = convert_to_torch(transformed_image, transformed_mask)\n",
    "plot_image_and_mask(image_torch, mask_torch)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4f9b89-04d7-45a0-8ff2-68209fb468c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_and_mask(image, mask): \n",
    "    image = image/ 255.0\n",
    "    mask = mask\n",
    "\n",
    "    # Plot side by side with the mask and mask overlain\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Plot the original image\n",
    "    axes[0].imshow(image.permute(1, 2, 0))\n",
    "    axes[0].set_title('Original Image')\n",
    "\n",
    "    # Plot the mask\n",
    "    axes[1].imshow(mask.permute(1, 2, 0), cmap='viridis')\n",
    "    axes[1].set_title('Mask')\n",
    "\n",
    "    # Overlay the mask on the image\n",
    "    axes[2].imshow(image.permute(1, 2, 0))\n",
    "    axes[2].imshow(mask.permute(1, 2, 0), cmap='viridis', alpha=0.6)  # Set alpha to less than 1\n",
    "    axes[2].set_title('Mask Overlain on Image')\n",
    "\n",
    "    # Display the plots\n",
    "    plt.show()\n",
    "\n",
    "def convert_to_torch(image, mask):\n",
    "    \n",
    "    tensor_image = torch.from_numpy(image)\n",
    "    tensor_image = tensor_image.permute(2,0, 1)\n",
    "\n",
    "    tensor_mask = torch.from_numpy(mask)\n",
    "    tensor_mask = tensor_mask.permute(2,0, 1) / 255\n",
    "    \n",
    "    tensor_mask = tensor_mask[2:, :, :]\n",
    "\n",
    "    # add padding\n",
    "    pad_height = max(992 - tensor_image.size(1), 0)\n",
    "    pad_width = max(416 - tensor_image.size(2), 0)\n",
    "\n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "\n",
    "    padded_image = transforms.functional.pad(tensor_image, (pad_left, pad_bottom, pad_right, pad_top), fill=255)\n",
    "    padded_mask = transforms.functional.pad(tensor_mask, (pad_left, pad_bottom, pad_right, pad_top), fill=0)\n",
    "\n",
    "\n",
    "    return torch.tensor(padded_image, dtype=torch.float32), torch.tensor(padded_mask, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fdcdf84-3404-4379-87b0-655ef033cc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UnetPlusPlus:\n\tMissing key(s) in state_dict: \"encoder.stem.conv.weight\", \"encoder.stem.bn.weight\", \"encoder.stem.bn.bias\", \"encoder.stem.bn.running_mean\", \"encoder.stem.bn.running_var\", \"encoder.s1.b1.conv1.conv.weight\", \"encoder.s1.b1.conv1.bn.weight\", \"encoder.s1.b1.conv1.bn.bias\", \"encoder.s1.b1.conv1.bn.running_mean\", \"encoder.s1.b1.conv1.bn.running_var\", \"encoder.s1.b1.conv2.conv.weight\", \"encoder.s1.b1.conv2.bn.weight\", \"encoder.s1.b1.conv2.bn.bias\", \"encoder.s1.b1.conv2.bn.running_mean\", \"encoder.s1.b1.conv2.bn.running_var\", \"encoder.s1.b1.conv3.conv.weight\", \"encoder.s1.b1.conv3.bn.weight\", \"encoder.s1.b1.conv3.bn.bias\", \"encoder.s1.b1.conv3.bn.running_mean\", \"encoder.s1.b1.conv3.bn.running_var\", \"encoder.s1.b1.downsample.conv.weight\", \"encoder.s1.b1.downsample.bn.weight\", \"encoder.s1.b1.downsample.bn.bias\", \"encoder.s1.b1.downsample.bn.running_mean\", \"encoder.s1.b1.downsample.bn.running_var\", \"encoder.s1.b2.conv1.conv.weight\", \"encoder.s1.b2.conv1.bn.weight\", \"encoder.s1.b2.conv1.bn.bias\", \"encoder.s1.b2.conv1.bn.running_mean\", \"encoder.s1.b2.conv1.bn.running_var\", \"encoder.s1.b2.conv2.conv.weight\", \"encoder.s1.b2.conv2.bn.weight\", \"encoder.s1.b2.conv2.bn.bias\", \"encoder.s1.b2.conv2.bn.running_mean\", \"encoder.s1.b2.conv2.bn.running_var\", \"encoder.s1.b2.conv3.conv.weight\", \"encoder.s1.b2.conv3.bn.weight\", \"encoder.s1.b2.conv3.bn.bias\", \"encoder.s1.b2.conv3.bn.running_mean\", \"encoder.s1.b2.conv3.bn.running_var\", \"encoder.s2.b1.conv1.conv.weight\", \"encoder.s2.b1.conv1.bn.weight\", \"encoder.s2.b1.conv1.bn.bias\", \"encoder.s2.b1.conv1.bn.running_mean\", \"encoder.s2.b1.conv1.bn.running_var\", \"encoder.s2.b1.conv2.conv.weight\", \"encoder.s2.b1.conv2.bn.weight\", \"encoder.s2.b1.conv2.bn.bias\", \"encoder.s2.b1.conv2.bn.running_mean\", \"encoder.s2.b1.conv2.bn.running_var\", \"encoder.s2.b1.conv3.conv.weight\", \"encoder.s2.b1.conv3.bn.weight\", \"encoder.s2.b1.conv3.bn.bias\", \"encoder.s2.b1.conv3.bn.running_mean\", \"encoder.s2.b1.conv3.bn.running_var\", \"encoder.s2.b1.downsample.conv.weight\", \"encoder.s2.b1.downsample.bn.weight\", \"encoder.s2.b1.downsample.bn.bias\", \"encoder.s2.b1.downsample.bn.running_mean\", \"encoder.s2.b1.downsample.bn.running_var\", \"encoder.s2.b2.conv1.conv.weight\", \"encoder.s2.b2.conv1.bn.weight\", \"encoder.s2.b2.conv1.bn.bias\", \"encoder.s2.b2.conv1.bn.running_mean\", \"encoder.s2.b2.conv1.bn.running_var\", \"encoder.s2.b2.conv2.conv.weight\", \"encoder.s2.b2.conv2.bn.weight\", \"encoder.s2.b2.conv2.bn.bias\", \"encoder.s2.b2.conv2.bn.running_mean\", \"encoder.s2.b2.conv2.bn.running_var\", \"encoder.s2.b2.conv3.conv.weight\", \"encoder.s2.b2.conv3.bn.weight\", \"encoder.s2.b2.conv3.bn.bias\", \"encoder.s2.b2.conv3.bn.running_mean\", \"encoder.s2.b2.conv3.bn.running_var\", \"encoder.s2.b3.conv1.conv.weight\", \"encoder.s2.b3.conv1.bn.weight\", \"encoder.s2.b3.conv1.bn.bias\", \"encoder.s2.b3.conv1.bn.running_mean\", \"encoder.s2.b3.conv1.bn.running_var\", \"encoder.s2.b3.conv2.conv.weight\", \"encoder.s2.b3.conv2.bn.weight\", \"encoder.s2.b3.conv2.bn.bias\", \"encoder.s2.b3.conv2.bn.running_mean\", \"encoder.s2.b3.conv2.bn.running_var\", \"encoder.s2.b3.conv3.conv.weight\", \"encoder.s2.b3.conv3.bn.weight\", \"encoder.s2.b3.conv3.bn.bias\", \"encoder.s2.b3.conv3.bn.running_mean\", \"encoder.s2.b3.conv3.bn.running_var\", \"encoder.s2.b4.conv1.conv.weight\", \"encoder.s2.b4.conv1.bn.weight\", \"encoder.s2.b4.conv1.bn.bias\", \"encoder.s2.b4.conv1.bn.running_mean\", \"encoder.s2.b4.conv1.bn.running_var\", \"encoder.s2.b4.conv2.conv.weight\", \"encoder.s2.b4.conv2.bn.weight\", \"encoder.s2.b4.conv2.bn.bias\", \"encoder.s2.b4.conv2.bn.running_mean\", \"encoder.s2.b4.conv2.bn.running_var\", \"encoder.s2.b4.conv3.conv.weight\", \"encoder.s2.b4.conv3.bn.weight\", \"encoder.s2.b4.conv3.bn.bias\", \"encoder.s2.b4.conv3.bn.running_mean\", \"encoder.s2.b4.conv3.bn.running_var\", \"encoder.s2.b5.conv1.conv.weight\", \"encoder.s2.b5.conv1.bn.weight\", \"encoder.s2.b5.conv1.bn.bias\", \"encoder.s2.b5.conv1.bn.running_mean\", \"encoder.s2.b5.conv1.bn.running_var\", \"encoder.s2.b5.conv2.conv.weight\", \"encoder.s2.b5.conv2.bn.weight\", \"encoder.s2.b5.conv2.bn.bias\", \"encoder.s2.b5.conv2.bn.running_mean\", \"encoder.s2.b5.conv2.bn.running_var\", \"encoder.s2.b5.conv3.conv.weight\", \"encoder.s2.b5.conv3.bn.weight\", \"encoder.s2.b5.conv3.bn.bias\", \"encoder.s2.b5.conv3.bn.running_mean\", \"encoder.s2.b5.conv3.bn.running_var\", \"encoder.s3.b1.conv1.conv.weight\", \"encoder.s3.b1.conv1.bn.weight\", \"encoder.s3.b1.conv1.bn.bias\", \"encoder.s3.b1.conv1.bn.running_mean\", \"encoder.s3.b1.conv1.bn.running_var\", \"encoder.s3.b1.conv2.conv.weight\", \"encoder.s3.b1.conv2.bn.weight\", \"encoder.s3.b1.conv2.bn.bias\", \"encoder.s3.b1.conv2.bn.running_mean\", \"encoder.s3.b1.conv2.bn.running_var\", \"encoder.s3.b1.conv3.conv.weight\", \"encoder.s3.b1.conv3.bn.weight\", \"encoder.s3.b1.conv3.bn.bias\", \"encoder.s3.b1.conv3.bn.running_mean\", \"encoder.s3.b1.conv3.bn.running_var\", \"encoder.s3.b1.downsample.conv.weight\", \"encoder.s3.b1.downsample.bn.weight\", \"encoder.s3.b1.downsample.bn.bias\", \"encoder.s3.b1.downsample.bn.running_mean\", \"encoder.s3.b1.downsample.bn.running_var\", \"encoder.s3.b2.conv1.conv.weight\", \"encoder.s3.b2.conv1.bn.weight\", \"encoder.s3.b2.conv1.bn.bias\", \"encoder.s3.b2.conv1.bn.running_mean\", \"encoder.s3.b2.conv1.bn.running_var\", \"encoder.s3.b2.conv2.conv.weight\", \"encoder.s3.b2.conv2.bn.weight\", \"encoder.s3.b2.conv2.bn.bias\", \"encoder.s3.b2.conv2.bn.running_mean\", \"encoder.s3.b2.conv2.bn.running_var\", \"encoder.s3.b2.conv3.conv.weight\", \"encoder.s3.b2.conv3.bn.weight\", \"encoder.s3.b2.conv3.bn.bias\", \"encoder.s3.b2.conv3.bn.running_mean\", \"encoder.s3.b2.conv3.bn.running_var\", \"encoder.s3.b3.conv1.conv.weight\", \"encoder.s3.b3.conv1.bn.weight\", \"encoder.s3.b3.conv1.bn.bias\", \"encoder.s3.b3.conv1.bn.running_mean\", \"encoder.s3.b3.conv1.bn.running_var\", \"encoder.s3.b3.conv2.conv.weight\", \"encoder.s3.b3.conv2.bn.weight\", \"encoder.s3.b3.conv2.bn.bias\", \"encoder.s3.b3.conv2.bn.running_mean\", \"encoder.s3.b3.conv2.bn.running_var\", \"encoder.s3.b3.conv3.conv.weight\", \"encoder.s3.b3.conv3.bn.weight\", \"encoder.s3.b3.conv3.bn.bias\", \"encoder.s3.b3.conv3.bn.running_mean\", \"encoder.s3.b3.conv3.bn.running_var\", \"encoder.s3.b4.conv1.conv.weight\", \"encoder.s3.b4.conv1.bn.weight\", \"encoder.s3.b4.conv1.bn.bias\", \"encoder.s3.b4.conv1.bn.running_mean\", \"encoder.s3.b4.conv1.bn.running_var\", \"encoder.s3.b4.conv2.conv.weight\", \"encoder.s3.b4.conv2.bn.weight\", \"encoder.s3.b4.conv2.bn.bias\", \"encoder.s3.b4.conv2.bn.running_mean\", \"encoder.s3.b4.conv2.bn.running_var\", \"encoder.s3.b4.conv3.conv.weight\", \"encoder.s3.b4.conv3.bn.weight\", \"encoder.s3.b4.conv3.bn.bias\", \"encoder.s3.b4.conv3.bn.running_mean\", \"encoder.s3.b4.conv3.bn.running_var\", \"encoder.s3.b5.conv1.conv.weight\", \"encoder.s3.b5.conv1.bn.weight\", \"encoder.s3.b5.conv1.bn.bias\", \"encoder.s3.b5.conv1.bn.running_mean\", \"encoder.s3.b5.conv1.bn.running_var\", \"encoder.s3.b5.conv2.conv.weight\", \"encoder.s3.b5.conv2.bn.weight\", \"encoder.s3.b5.conv2.bn.bias\", \"encoder.s3.b5.conv2.bn.running_mean\", \"encoder.s3.b5.conv2.bn.running_var\", \"encoder.s3.b5.conv3.conv.weight\", \"encoder.s3.b5.conv3.bn.weight\", \"encoder.s3.b5.conv3.bn.bias\", \"encoder.s3.b5.conv3.bn.running_mean\", \"encoder.s3.b5.conv3.bn.running_var\", \"encoder.s3.b6.conv1.conv.weight\", \"encoder.s3.b6.conv1.bn.weight\", \"encoder.s3.b6.conv1.bn.bias\", \"encoder.s3.b6.conv1.bn.running_mean\", \"encoder.s3.b6.conv1.bn.running_var\", \"encoder.s3.b6.conv2.conv.weight\", \"encoder.s3.b6.conv2.bn.weight\", \"encoder.s3.b6.conv2.bn.bias\", \"encoder.s3.b6.conv2.bn.running_mean\", \"encoder.s3.b6.conv2.bn.running_var\", \"encoder.s3.b6.conv3.conv.weight\", \"encoder.s3.b6.conv3.bn.weight\", \"encoder.s3.b6.conv3.bn.bias\", \"encoder.s3.b6.conv3.bn.running_mean\", \"encoder.s3.b6.conv3.bn.running_var\", \"encoder.s3.b7.conv1.conv.weight\", \"encoder.s3.b7.conv1.bn.weight\", \"encoder.s3.b7.conv1.bn.bias\", \"encoder.s3.b7.conv1.bn.running_mean\", \"encoder.s3.b7.conv1.bn.running_var\", \"encoder.s3.b7.conv2.conv.weight\", \"encoder.s3.b7.conv2.bn.weight\", \"encoder.s3.b7.conv2.bn.bias\", \"encoder.s3.b7.conv2.bn.running_mean\", \"encoder.s3.b7.conv2.bn.running_var\", \"encoder.s3.b7.conv3.conv.weight\", \"encoder.s3.b7.conv3.bn.weight\", \"encoder.s3.b7.conv3.bn.bias\", \"encoder.s3.b7.conv3.bn.running_mean\", \"encoder.s3.b7.conv3.bn.running_var\", \"encoder.s3.b8.conv1.conv.weight\", \"encoder.s3.b8.conv1.bn.weight\", \"encoder.s3.b8.conv1.bn.bias\", \"encoder.s3.b8.conv1.bn.running_mean\", \"encoder.s3.b8.conv1.bn.running_var\", \"encoder.s3.b8.conv2.conv.weight\", \"encoder.s3.b8.conv2.bn.weight\", \"encoder.s3.b8.conv2.bn.bias\", \"encoder.s3.b8.conv2.bn.running_mean\", \"encoder.s3.b8.conv2.bn.running_var\", \"encoder.s3.b8.conv3.conv.weight\", \"encoder.s3.b8.conv3.bn.weight\", \"encoder.s3.b8.conv3.bn.bias\", \"encoder.s3.b8.conv3.bn.running_mean\", \"encoder.s3.b8.conv3.bn.running_var\", \"encoder.s3.b9.conv1.conv.weight\", \"encoder.s3.b9.conv1.bn.weight\", \"encoder.s3.b9.conv1.bn.bias\", \"encoder.s3.b9.conv1.bn.running_mean\", \"encoder.s3.b9.conv1.bn.running_var\", \"encoder.s3.b9.conv2.conv.weight\", \"encoder.s3.b9.conv2.bn.weight\", \"encoder.s3.b9.conv2.bn.bias\", \"encoder.s3.b9.conv2.bn.running_mean\", \"encoder.s3.b9.conv2.bn.running_var\", \"encoder.s3.b9.conv3.conv.weight\", \"encoder.s3.b9.conv3.bn.weight\", \"encoder.s3.b9.conv3.bn.bias\", \"encoder.s3.b9.conv3.bn.running_mean\", \"encoder.s3.b9.conv3.bn.running_var\", \"encoder.s3.b10.conv1.conv.weight\", \"encoder.s3.b10.conv1.bn.weight\", \"encoder.s3.b10.conv1.bn.bias\", \"encoder.s3.b10.conv1.bn.running_mean\", \"encoder.s3.b10.conv1.bn.running_var\", \"encoder.s3.b10.conv2.conv.weight\", \"encoder.s3.b10.conv2.bn.weight\", \"encoder.s3.b10.conv2.bn.bias\", \"encoder.s3.b10.conv2.bn.running_mean\", \"encoder.s3.b10.conv2.bn.running_var\", \"encoder.s3.b10.conv3.conv.weight\", \"encoder.s3.b10.conv3.bn.weight\", \"encoder.s3.b10.conv3.bn.bias\", \"encoder.s3.b10.conv3.bn.running_mean\", \"encoder.s3.b10.conv3.bn.running_var\", \"encoder.s3.b11.conv1.conv.weight\", \"encoder.s3.b11.conv1.bn.weight\", \"encoder.s3.b11.conv1.bn.bias\", \"encoder.s3.b11.conv1.bn.running_mean\", \"encoder.s3.b11.conv1.bn.running_var\", \"encoder.s3.b11.conv2.conv.weight\", \"encoder.s3.b11.conv2.bn.weight\", \"encoder.s3.b11.conv2.bn.bias\", \"encoder.s3.b11.conv2.bn.running_mean\", \"encoder.s3.b11.conv2.bn.running_var\", \"encoder.s3.b11.conv3.conv.weight\", \"encoder.s3.b11.conv3.bn.weight\", \"encoder.s3.b11.conv3.bn.bias\", \"encoder.s3.b11.conv3.bn.running_mean\", \"encoder.s3.b11.conv3.bn.running_var\", \"encoder.s3.b12.conv1.conv.weight\", \"encoder.s3.b12.conv1.bn.weight\", \"encoder.s3.b12.conv1.bn.bias\", \"encoder.s3.b12.conv1.bn.running_mean\", \"encoder.s3.b12.conv1.bn.running_var\", \"encoder.s3.b12.conv2.conv.weight\", \"encoder.s3.b12.conv2.bn.weight\", \"encoder.s3.b12.conv2.bn.bias\", \"encoder.s3.b12.conv2.bn.running_mean\", \"encoder.s3.b12.conv2.bn.running_var\", \"encoder.s3.b12.conv3.conv.weight\", \"encoder.s3.b12.conv3.bn.weight\", \"encoder.s3.b12.conv3.bn.bias\", \"encoder.s3.b12.conv3.bn.running_mean\", \"encoder.s3.b12.conv3.bn.running_var\", \"encoder.s3.b13.conv1.conv.weight\", \"encoder.s3.b13.conv1.bn.weight\", \"encoder.s3.b13.conv1.bn.bias\", \"encoder.s3.b13.conv1.bn.running_mean\", \"encoder.s3.b13.conv1.bn.running_var\", \"encoder.s3.b13.conv2.conv.weight\", \"encoder.s3.b13.conv2.bn.weight\", \"encoder.s3.b13.conv2.bn.bias\", \"encoder.s3.b13.conv2.bn.running_mean\", \"encoder.s3.b13.conv2.bn.running_var\", \"encoder.s3.b13.conv3.conv.weight\", \"encoder.s3.b13.conv3.bn.weight\", \"encoder.s3.b13.conv3.bn.bias\", \"encoder.s3.b13.conv3.bn.running_mean\", \"encoder.s3.b13.conv3.bn.running_var\", \"encoder.s3.b14.conv1.conv.weight\", \"encoder.s3.b14.conv1.bn.weight\", \"encoder.s3.b14.conv1.bn.bias\", \"encoder.s3.b14.conv1.bn.running_mean\", \"encoder.s3.b14.conv1.bn.running_var\", \"encoder.s3.b14.conv2.conv.weight\", \"encoder.s3.b14.conv2.bn.weight\", \"encoder.s3.b14.conv2.bn.bias\", \"encoder.s3.b14.conv2.bn.running_mean\", \"encoder.s3.b14.conv2.bn.running_var\", \"encoder.s3.b14.conv3.conv.weight\", \"encoder.s3.b14.conv3.bn.weight\", \"encoder.s3.b14.conv3.bn.bias\", \"encoder.s3.b14.conv3.bn.running_mean\", \"encoder.s3.b14.conv3.bn.running_var\", \"encoder.s4.b1.conv1.conv.weight\", \"encoder.s4.b1.conv1.bn.weight\", \"encoder.s4.b1.conv1.bn.bias\", \"encoder.s4.b1.conv1.bn.running_mean\", \"encoder.s4.b1.conv1.bn.running_var\", \"encoder.s4.b1.conv2.conv.weight\", \"encoder.s4.b1.conv2.bn.weight\", \"encoder.s4.b1.conv2.bn.bias\", \"encoder.s4.b1.conv2.bn.running_mean\", \"encoder.s4.b1.conv2.bn.running_var\", \"encoder.s4.b1.conv3.conv.weight\", \"encoder.s4.b1.conv3.bn.weight\", \"encoder.s4.b1.conv3.bn.bias\", \"encoder.s4.b1.conv3.bn.running_mean\", \"encoder.s4.b1.conv3.bn.running_var\", \"encoder.s4.b1.downsample.conv.weight\", \"encoder.s4.b1.downsample.bn.weight\", \"encoder.s4.b1.downsample.bn.bias\", \"encoder.s4.b1.downsample.bn.running_mean\", \"encoder.s4.b1.downsample.bn.running_var\", \"encoder.s4.b2.conv1.conv.weight\", \"encoder.s4.b2.conv1.bn.weight\", \"encoder.s4.b2.conv1.bn.bias\", \"encoder.s4.b2.conv1.bn.running_mean\", \"encoder.s4.b2.conv1.bn.running_var\", \"encoder.s4.b2.conv2.conv.weight\", \"encoder.s4.b2.conv2.bn.weight\", \"encoder.s4.b2.conv2.bn.bias\", \"encoder.s4.b2.conv2.bn.running_mean\", \"encoder.s4.b2.conv2.bn.running_var\", \"encoder.s4.b2.conv3.conv.weight\", \"encoder.s4.b2.conv3.bn.weight\", \"encoder.s4.b2.conv3.bn.bias\", \"encoder.s4.b2.conv3.bn.running_mean\", \"encoder.s4.b2.conv3.bn.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\". \n\tsize mismatch for decoder.blocks.x_0_0.conv1.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1920, 3, 3]).\n\tsize mismatch for decoder.blocks.x_0_1.conv1.0.weight: copying a param with shape torch.Size([128, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 736, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.0.weight: copying a param with shape torch.Size([128, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 800, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.0.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 240, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_0_2.conv1.0.weight: copying a param with shape torch.Size([64, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 368, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 400, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 320, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_0_3.conv1.0.weight: copying a param with shape torch.Size([32, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 192, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 176, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 144, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.0.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 112, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/notebooks/Testing/CV-131/MODEL-UnetPlusPlusresnet34CV-131_FINAL.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mUnetPlusPlus(\n\u001b[1;32m      6\u001b[0m     encoder_name\u001b[38;5;241m=\u001b[39mENCODER_NAME,           \u001b[38;5;66;03m# choose encoder, e.g. mobilenet_v2 or efficientnet-b7\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,                        \u001b[38;5;66;03m# model input channels (1 for gray-scale images, 3 for RGB, etc.)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,                            \u001b[38;5;66;03m# model output channels (number of classes in your dataset)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_image\u001b[39m(model, image, mask): \n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UnetPlusPlus:\n\tMissing key(s) in state_dict: \"encoder.stem.conv.weight\", \"encoder.stem.bn.weight\", \"encoder.stem.bn.bias\", \"encoder.stem.bn.running_mean\", \"encoder.stem.bn.running_var\", \"encoder.s1.b1.conv1.conv.weight\", \"encoder.s1.b1.conv1.bn.weight\", \"encoder.s1.b1.conv1.bn.bias\", \"encoder.s1.b1.conv1.bn.running_mean\", \"encoder.s1.b1.conv1.bn.running_var\", \"encoder.s1.b1.conv2.conv.weight\", \"encoder.s1.b1.conv2.bn.weight\", \"encoder.s1.b1.conv2.bn.bias\", \"encoder.s1.b1.conv2.bn.running_mean\", \"encoder.s1.b1.conv2.bn.running_var\", \"encoder.s1.b1.conv3.conv.weight\", \"encoder.s1.b1.conv3.bn.weight\", \"encoder.s1.b1.conv3.bn.bias\", \"encoder.s1.b1.conv3.bn.running_mean\", \"encoder.s1.b1.conv3.bn.running_var\", \"encoder.s1.b1.downsample.conv.weight\", \"encoder.s1.b1.downsample.bn.weight\", \"encoder.s1.b1.downsample.bn.bias\", \"encoder.s1.b1.downsample.bn.running_mean\", \"encoder.s1.b1.downsample.bn.running_var\", \"encoder.s1.b2.conv1.conv.weight\", \"encoder.s1.b2.conv1.bn.weight\", \"encoder.s1.b2.conv1.bn.bias\", \"encoder.s1.b2.conv1.bn.running_mean\", \"encoder.s1.b2.conv1.bn.running_var\", \"encoder.s1.b2.conv2.conv.weight\", \"encoder.s1.b2.conv2.bn.weight\", \"encoder.s1.b2.conv2.bn.bias\", \"encoder.s1.b2.conv2.bn.running_mean\", \"encoder.s1.b2.conv2.bn.running_var\", \"encoder.s1.b2.conv3.conv.weight\", \"encoder.s1.b2.conv3.bn.weight\", \"encoder.s1.b2.conv3.bn.bias\", \"encoder.s1.b2.conv3.bn.running_mean\", \"encoder.s1.b2.conv3.bn.running_var\", \"encoder.s2.b1.conv1.conv.weight\", \"encoder.s2.b1.conv1.bn.weight\", \"encoder.s2.b1.conv1.bn.bias\", \"encoder.s2.b1.conv1.bn.running_mean\", \"encoder.s2.b1.conv1.bn.running_var\", \"encoder.s2.b1.conv2.conv.weight\", \"encoder.s2.b1.conv2.bn.weight\", \"encoder.s2.b1.conv2.bn.bias\", \"encoder.s2.b1.conv2.bn.running_mean\", \"encoder.s2.b1.conv2.bn.running_var\", \"encoder.s2.b1.conv3.conv.weight\", \"encoder.s2.b1.conv3.bn.weight\", \"encoder.s2.b1.conv3.bn.bias\", \"encoder.s2.b1.conv3.bn.running_mean\", \"encoder.s2.b1.conv3.bn.running_var\", \"encoder.s2.b1.downsample.conv.weight\", \"encoder.s2.b1.downsample.bn.weight\", \"encoder.s2.b1.downsample.bn.bias\", \"encoder.s2.b1.downsample.bn.running_mean\", \"encoder.s2.b1.downsample.bn.running_var\", \"encoder.s2.b2.conv1.conv.weight\", \"encoder.s2.b2.conv1.bn.weight\", \"encoder.s2.b2.conv1.bn.bias\", \"encoder.s2.b2.conv1.bn.running_mean\", \"encoder.s2.b2.conv1.bn.running_var\", \"encoder.s2.b2.conv2.conv.weight\", \"encoder.s2.b2.conv2.bn.weight\", \"encoder.s2.b2.conv2.bn.bias\", \"encoder.s2.b2.conv2.bn.running_mean\", \"encoder.s2.b2.conv2.bn.running_var\", \"encoder.s2.b2.conv3.conv.weight\", \"encoder.s2.b2.conv3.bn.weight\", \"encoder.s2.b2.conv3.bn.bias\", \"encoder.s2.b2.conv3.bn.running_mean\", \"encoder.s2.b2.conv3.bn.running_var\", \"encoder.s2.b3.conv1.conv.weight\", \"encoder.s2.b3.conv1.bn.weight\", \"encoder.s2.b3.conv1.bn.bias\", \"encoder.s2.b3.conv1.bn.running_mean\", \"encoder.s2.b3.conv1.bn.running_var\", \"encoder.s2.b3.conv2.conv.weight\", \"encoder.s2.b3.conv2.bn.weight\", \"encoder.s2.b3.conv2.bn.bias\", \"encoder.s2.b3.conv2.bn.running_mean\", \"encoder.s2.b3.conv2.bn.running_var\", \"encoder.s2.b3.conv3.conv.weight\", \"encoder.s2.b3.conv3.bn.weight\", \"encoder.s2.b3.conv3.bn.bias\", \"encoder.s2.b3.conv3.bn.running_mean\", \"encoder.s2.b3.conv3.bn.running_var\", \"encoder.s2.b4.conv1.conv.weight\", \"encoder.s2.b4.conv1.bn.weight\", \"encoder.s2.b4.conv1.bn.bias\", \"encoder.s2.b4.conv1.bn.running_mean\", \"encoder.s2.b4.conv1.bn.running_var\", \"encoder.s2.b4.conv2.conv.weight\", \"encoder.s2.b4.conv2.bn.weight\", \"encoder.s2.b4.conv2.bn.bias\", \"encoder.s2.b4.conv2.bn.running_mean\", \"encoder.s2.b4.conv2.bn.running_var\", \"encoder.s2.b4.conv3.conv.weight\", \"encoder.s2.b4.conv3.bn.weight\", \"encoder.s2.b4.conv3.bn.bias\", \"encoder.s2.b4.conv3.bn.running_mean\", \"encoder.s2.b4.conv3.bn.running_var\", \"encoder.s2.b5.conv1.conv.weight\", \"encoder.s2.b5.conv1.bn.weight\", \"encoder.s2.b5.conv1.bn.bias\", \"encoder.s2.b5.conv1.bn.running_mean\", \"encoder.s2.b5.conv1.bn.running_var\", \"encoder.s2.b5.conv2.conv.weight\", \"encoder.s2.b5.conv2.bn.weight\", \"encoder.s2.b5.conv2.bn.bias\", \"encoder.s2.b5.conv2.bn.running_mean\", \"encoder.s2.b5.conv2.bn.running_var\", \"encoder.s2.b5.conv3.conv.weight\", \"encoder.s2.b5.conv3.bn.weight\", \"encoder.s2.b5.conv3.bn.bias\", \"encoder.s2.b5.conv3.bn.running_mean\", \"encoder.s2.b5.conv3.bn.running_var\", \"encoder.s3.b1.conv1.conv.weight\", \"encoder.s3.b1.conv1.bn.weight\", \"encoder.s3.b1.conv1.bn.bias\", \"encoder.s3.b1.conv1.bn.running_mean\", \"encoder.s3.b1.conv1.bn.running_var\", \"encoder.s3.b1.conv2.conv.weight\", \"encoder.s3.b1.conv2.bn.weight\", \"encoder.s3.b1.conv2.bn.bias\", \"encoder.s3.b1.conv2.bn.running_mean\", \"encoder.s3.b1.conv2.bn.running_var\", \"encoder.s3.b1.conv3.conv.weight\", \"encoder.s3.b1.conv3.bn.weight\", \"encoder.s3.b1.conv3.bn.bias\", \"encoder.s3.b1.conv3.bn.running_mean\", \"encoder.s3.b1.conv3.bn.running_var\", \"encoder.s3.b1.downsample.conv.weight\", \"encoder.s3.b1.downsample.bn.weight\", \"encoder.s3.b1.downsample.bn.bias\", \"encoder.s3.b1.downsample.bn.running_mean\", \"encoder.s3.b1.downsample.bn.running_var\", \"encoder.s3.b2.conv1.conv.weight\", \"encoder.s3.b2.conv1.bn.weight\", \"encoder.s3.b2.conv1.bn.bias\", \"encoder.s3.b2.conv1.bn.running_mean\", \"encoder.s3.b2.conv1.bn.running_var\", \"encoder.s3.b2.conv2.conv.weight\", \"encoder.s3.b2.conv2.bn.weight\", \"encoder.s3.b2.conv2.bn.bias\", \"encoder.s3.b2.conv2.bn.running_mean\", \"encoder.s3.b2.conv2.bn.running_var\", \"encoder.s3.b2.conv3.conv.weight\", \"encoder.s3.b2.conv3.bn.weight\", \"encoder.s3.b2.conv3.bn.bias\", \"encoder.s3.b2.conv3.bn.running_mean\", \"encoder.s3.b2.conv3.bn.running_var\", \"encoder.s3.b3.conv1.conv.weight\", \"encoder.s3.b3.conv1.bn.weight\", \"encoder.s3.b3.conv1.bn.bias\", \"encoder.s3.b3.conv1.bn.running_mean\", \"encoder.s3.b3.conv1.bn.running_var\", \"encoder.s3.b3.conv2.conv.weight\", \"encoder.s3.b3.conv2.bn.weight\", \"encoder.s3.b3.conv2.bn.bias\", \"encoder.s3.b3.conv2.bn.running_mean\", \"encoder.s3.b3.conv2.bn.running_var\", \"encoder.s3.b3.conv3.conv.weight\", \"encoder.s3.b3.conv3.bn.weight\", \"encoder.s3.b3.conv3.bn.bias\", \"encoder.s3.b3.conv3.bn.running_mean\", \"encoder.s3.b3.conv3.bn.running_var\", \"encoder.s3.b4.conv1.conv.weight\", \"encoder.s3.b4.conv1.bn.weight\", \"encoder.s3.b4.conv1.bn.bias\", \"encoder.s3.b4.conv1.bn.running_mean\", \"encoder.s3.b4.conv1.bn.running_var\", \"encoder.s3.b4.conv2.conv.weight\", \"encoder.s3.b4.conv2.bn.weight\", \"encoder.s3.b4.conv2.bn.bias\", \"encoder.s3.b4.conv2.bn.running_mean\", \"encoder.s3.b4.conv2.bn.running_var\", \"encoder.s3.b4.conv3.conv.weight\", \"encoder.s3.b4.conv3.bn.weight\", \"encoder.s3.b4.conv3.bn.bias\", \"encoder.s3.b4.conv3.bn.running_mean\", \"encoder.s3.b4.conv3.bn.running_var\", \"encoder.s3.b5.conv1.conv.weight\", \"encoder.s3.b5.conv1.bn.weight\", \"encoder.s3.b5.conv1.bn.bias\", \"encoder.s3.b5.conv1.bn.running_mean\", \"encoder.s3.b5.conv1.bn.running_var\", \"encoder.s3.b5.conv2.conv.weight\", \"encoder.s3.b5.conv2.bn.weight\", \"encoder.s3.b5.conv2.bn.bias\", \"encoder.s3.b5.conv2.bn.running_mean\", \"encoder.s3.b5.conv2.bn.running_var\", \"encoder.s3.b5.conv3.conv.weight\", \"encoder.s3.b5.conv3.bn.weight\", \"encoder.s3.b5.conv3.bn.bias\", \"encoder.s3.b5.conv3.bn.running_mean\", \"encoder.s3.b5.conv3.bn.running_var\", \"encoder.s3.b6.conv1.conv.weight\", \"encoder.s3.b6.conv1.bn.weight\", \"encoder.s3.b6.conv1.bn.bias\", \"encoder.s3.b6.conv1.bn.running_mean\", \"encoder.s3.b6.conv1.bn.running_var\", \"encoder.s3.b6.conv2.conv.weight\", \"encoder.s3.b6.conv2.bn.weight\", \"encoder.s3.b6.conv2.bn.bias\", \"encoder.s3.b6.conv2.bn.running_mean\", \"encoder.s3.b6.conv2.bn.running_var\", \"encoder.s3.b6.conv3.conv.weight\", \"encoder.s3.b6.conv3.bn.weight\", \"encoder.s3.b6.conv3.bn.bias\", \"encoder.s3.b6.conv3.bn.running_mean\", \"encoder.s3.b6.conv3.bn.running_var\", \"encoder.s3.b7.conv1.conv.weight\", \"encoder.s3.b7.conv1.bn.weight\", \"encoder.s3.b7.conv1.bn.bias\", \"encoder.s3.b7.conv1.bn.running_mean\", \"encoder.s3.b7.conv1.bn.running_var\", \"encoder.s3.b7.conv2.conv.weight\", \"encoder.s3.b7.conv2.bn.weight\", \"encoder.s3.b7.conv2.bn.bias\", \"encoder.s3.b7.conv2.bn.running_mean\", \"encoder.s3.b7.conv2.bn.running_var\", \"encoder.s3.b7.conv3.conv.weight\", \"encoder.s3.b7.conv3.bn.weight\", \"encoder.s3.b7.conv3.bn.bias\", \"encoder.s3.b7.conv3.bn.running_mean\", \"encoder.s3.b7.conv3.bn.running_var\", \"encoder.s3.b8.conv1.conv.weight\", \"encoder.s3.b8.conv1.bn.weight\", \"encoder.s3.b8.conv1.bn.bias\", \"encoder.s3.b8.conv1.bn.running_mean\", \"encoder.s3.b8.conv1.bn.running_var\", \"encoder.s3.b8.conv2.conv.weight\", \"encoder.s3.b8.conv2.bn.weight\", \"encoder.s3.b8.conv2.bn.bias\", \"encoder.s3.b8.conv2.bn.running_mean\", \"encoder.s3.b8.conv2.bn.running_var\", \"encoder.s3.b8.conv3.conv.weight\", \"encoder.s3.b8.conv3.bn.weight\", \"encoder.s3.b8.conv3.bn.bias\", \"encoder.s3.b8.conv3.bn.running_mean\", \"encoder.s3.b8.conv3.bn.running_var\", \"encoder.s3.b9.conv1.conv.weight\", \"encoder.s3.b9.conv1.bn.weight\", \"encoder.s3.b9.conv1.bn.bias\", \"encoder.s3.b9.conv1.bn.running_mean\", \"encoder.s3.b9.conv1.bn.running_var\", \"encoder.s3.b9.conv2.conv.weight\", \"encoder.s3.b9.conv2.bn.weight\", \"encoder.s3.b9.conv2.bn.bias\", \"encoder.s3.b9.conv2.bn.running_mean\", \"encoder.s3.b9.conv2.bn.running_var\", \"encoder.s3.b9.conv3.conv.weight\", \"encoder.s3.b9.conv3.bn.weight\", \"encoder.s3.b9.conv3.bn.bias\", \"encoder.s3.b9.conv3.bn.running_mean\", \"encoder.s3.b9.conv3.bn.running_var\", \"encoder.s3.b10.conv1.conv.weight\", \"encoder.s3.b10.conv1.bn.weight\", \"encoder.s3.b10.conv1.bn.bias\", \"encoder.s3.b10.conv1.bn.running_mean\", \"encoder.s3.b10.conv1.bn.running_var\", \"encoder.s3.b10.conv2.conv.weight\", \"encoder.s3.b10.conv2.bn.weight\", \"encoder.s3.b10.conv2.bn.bias\", \"encoder.s3.b10.conv2.bn.running_mean\", \"encoder.s3.b10.conv2.bn.running_var\", \"encoder.s3.b10.conv3.conv.weight\", \"encoder.s3.b10.conv3.bn.weight\", \"encoder.s3.b10.conv3.bn.bias\", \"encoder.s3.b10.conv3.bn.running_mean\", \"encoder.s3.b10.conv3.bn.running_var\", \"encoder.s3.b11.conv1.conv.weight\", \"encoder.s3.b11.conv1.bn.weight\", \"encoder.s3.b11.conv1.bn.bias\", \"encoder.s3.b11.conv1.bn.running_mean\", \"encoder.s3.b11.conv1.bn.running_var\", \"encoder.s3.b11.conv2.conv.weight\", \"encoder.s3.b11.conv2.bn.weight\", \"encoder.s3.b11.conv2.bn.bias\", \"encoder.s3.b11.conv2.bn.running_mean\", \"encoder.s3.b11.conv2.bn.running_var\", \"encoder.s3.b11.conv3.conv.weight\", \"encoder.s3.b11.conv3.bn.weight\", \"encoder.s3.b11.conv3.bn.bias\", \"encoder.s3.b11.conv3.bn.running_mean\", \"encoder.s3.b11.conv3.bn.running_var\", \"encoder.s3.b12.conv1.conv.weight\", \"encoder.s3.b12.conv1.bn.weight\", \"encoder.s3.b12.conv1.bn.bias\", \"encoder.s3.b12.conv1.bn.running_mean\", \"encoder.s3.b12.conv1.bn.running_var\", \"encoder.s3.b12.conv2.conv.weight\", \"encoder.s3.b12.conv2.bn.weight\", \"encoder.s3.b12.conv2.bn.bias\", \"encoder.s3.b12.conv2.bn.running_mean\", \"encoder.s3.b12.conv2.bn.running_var\", \"encoder.s3.b12.conv3.conv.weight\", \"encoder.s3.b12.conv3.bn.weight\", \"encoder.s3.b12.conv3.bn.bias\", \"encoder.s3.b12.conv3.bn.running_mean\", \"encoder.s3.b12.conv3.bn.running_var\", \"encoder.s3.b13.conv1.conv.weight\", \"encoder.s3.b13.conv1.bn.weight\", \"encoder.s3.b13.conv1.bn.bias\", \"encoder.s3.b13.conv1.bn.running_mean\", \"encoder.s3.b13.conv1.bn.running_var\", \"encoder.s3.b13.conv2.conv.weight\", \"encoder.s3.b13.conv2.bn.weight\", \"encoder.s3.b13.conv2.bn.bias\", \"encoder.s3.b13.conv2.bn.running_mean\", \"encoder.s3.b13.conv2.bn.running_var\", \"encoder.s3.b13.conv3.conv.weight\", \"encoder.s3.b13.conv3.bn.weight\", \"encoder.s3.b13.conv3.bn.bias\", \"encoder.s3.b13.conv3.bn.running_mean\", \"encoder.s3.b13.conv3.bn.running_var\", \"encoder.s3.b14.conv1.conv.weight\", \"encoder.s3.b14.conv1.bn.weight\", \"encoder.s3.b14.conv1.bn.bias\", \"encoder.s3.b14.conv1.bn.running_mean\", \"encoder.s3.b14.conv1.bn.running_var\", \"encoder.s3.b14.conv2.conv.weight\", \"encoder.s3.b14.conv2.bn.weight\", \"encoder.s3.b14.conv2.bn.bias\", \"encoder.s3.b14.conv2.bn.running_mean\", \"encoder.s3.b14.conv2.bn.running_var\", \"encoder.s3.b14.conv3.conv.weight\", \"encoder.s3.b14.conv3.bn.weight\", \"encoder.s3.b14.conv3.bn.bias\", \"encoder.s3.b14.conv3.bn.running_mean\", \"encoder.s3.b14.conv3.bn.running_var\", \"encoder.s4.b1.conv1.conv.weight\", \"encoder.s4.b1.conv1.bn.weight\", \"encoder.s4.b1.conv1.bn.bias\", \"encoder.s4.b1.conv1.bn.running_mean\", \"encoder.s4.b1.conv1.bn.running_var\", \"encoder.s4.b1.conv2.conv.weight\", \"encoder.s4.b1.conv2.bn.weight\", \"encoder.s4.b1.conv2.bn.bias\", \"encoder.s4.b1.conv2.bn.running_mean\", \"encoder.s4.b1.conv2.bn.running_var\", \"encoder.s4.b1.conv3.conv.weight\", \"encoder.s4.b1.conv3.bn.weight\", \"encoder.s4.b1.conv3.bn.bias\", \"encoder.s4.b1.conv3.bn.running_mean\", \"encoder.s4.b1.conv3.bn.running_var\", \"encoder.s4.b1.downsample.conv.weight\", \"encoder.s4.b1.downsample.bn.weight\", \"encoder.s4.b1.downsample.bn.bias\", \"encoder.s4.b1.downsample.bn.running_mean\", \"encoder.s4.b1.downsample.bn.running_var\", \"encoder.s4.b2.conv1.conv.weight\", \"encoder.s4.b2.conv1.bn.weight\", \"encoder.s4.b2.conv1.bn.bias\", \"encoder.s4.b2.conv1.bn.running_mean\", \"encoder.s4.b2.conv1.bn.running_var\", \"encoder.s4.b2.conv2.conv.weight\", \"encoder.s4.b2.conv2.bn.weight\", \"encoder.s4.b2.conv2.bn.bias\", \"encoder.s4.b2.conv2.bn.running_mean\", \"encoder.s4.b2.conv2.bn.running_var\", \"encoder.s4.b2.conv3.conv.weight\", \"encoder.s4.b2.conv3.bn.weight\", \"encoder.s4.b2.conv3.bn.bias\", \"encoder.s4.b2.conv3.bn.running_mean\", \"encoder.s4.b2.conv3.bn.running_var\". \n\tUnexpected key(s) in state_dict: \"encoder.conv1.weight\", \"encoder.bn1.weight\", \"encoder.bn1.bias\", \"encoder.bn1.running_mean\", \"encoder.bn1.running_var\", \"encoder.bn1.num_batches_tracked\", \"encoder.layer1.0.conv1.weight\", \"encoder.layer1.0.bn1.weight\", \"encoder.layer1.0.bn1.bias\", \"encoder.layer1.0.bn1.running_mean\", \"encoder.layer1.0.bn1.running_var\", \"encoder.layer1.0.bn1.num_batches_tracked\", \"encoder.layer1.0.conv2.weight\", \"encoder.layer1.0.bn2.weight\", \"encoder.layer1.0.bn2.bias\", \"encoder.layer1.0.bn2.running_mean\", \"encoder.layer1.0.bn2.running_var\", \"encoder.layer1.0.bn2.num_batches_tracked\", \"encoder.layer1.1.conv1.weight\", \"encoder.layer1.1.bn1.weight\", \"encoder.layer1.1.bn1.bias\", \"encoder.layer1.1.bn1.running_mean\", \"encoder.layer1.1.bn1.running_var\", \"encoder.layer1.1.bn1.num_batches_tracked\", \"encoder.layer1.1.conv2.weight\", \"encoder.layer1.1.bn2.weight\", \"encoder.layer1.1.bn2.bias\", \"encoder.layer1.1.bn2.running_mean\", \"encoder.layer1.1.bn2.running_var\", \"encoder.layer1.1.bn2.num_batches_tracked\", \"encoder.layer1.2.conv1.weight\", \"encoder.layer1.2.bn1.weight\", \"encoder.layer1.2.bn1.bias\", \"encoder.layer1.2.bn1.running_mean\", \"encoder.layer1.2.bn1.running_var\", \"encoder.layer1.2.bn1.num_batches_tracked\", \"encoder.layer1.2.conv2.weight\", \"encoder.layer1.2.bn2.weight\", \"encoder.layer1.2.bn2.bias\", \"encoder.layer1.2.bn2.running_mean\", \"encoder.layer1.2.bn2.running_var\", \"encoder.layer1.2.bn2.num_batches_tracked\", \"encoder.layer2.0.conv1.weight\", \"encoder.layer2.0.bn1.weight\", \"encoder.layer2.0.bn1.bias\", \"encoder.layer2.0.bn1.running_mean\", \"encoder.layer2.0.bn1.running_var\", \"encoder.layer2.0.bn1.num_batches_tracked\", \"encoder.layer2.0.conv2.weight\", \"encoder.layer2.0.bn2.weight\", \"encoder.layer2.0.bn2.bias\", \"encoder.layer2.0.bn2.running_mean\", \"encoder.layer2.0.bn2.running_var\", \"encoder.layer2.0.bn2.num_batches_tracked\", \"encoder.layer2.0.downsample.0.weight\", \"encoder.layer2.0.downsample.1.weight\", \"encoder.layer2.0.downsample.1.bias\", \"encoder.layer2.0.downsample.1.running_mean\", \"encoder.layer2.0.downsample.1.running_var\", \"encoder.layer2.0.downsample.1.num_batches_tracked\", \"encoder.layer2.1.conv1.weight\", \"encoder.layer2.1.bn1.weight\", \"encoder.layer2.1.bn1.bias\", \"encoder.layer2.1.bn1.running_mean\", \"encoder.layer2.1.bn1.running_var\", \"encoder.layer2.1.bn1.num_batches_tracked\", \"encoder.layer2.1.conv2.weight\", \"encoder.layer2.1.bn2.weight\", \"encoder.layer2.1.bn2.bias\", \"encoder.layer2.1.bn2.running_mean\", \"encoder.layer2.1.bn2.running_var\", \"encoder.layer2.1.bn2.num_batches_tracked\", \"encoder.layer2.2.conv1.weight\", \"encoder.layer2.2.bn1.weight\", \"encoder.layer2.2.bn1.bias\", \"encoder.layer2.2.bn1.running_mean\", \"encoder.layer2.2.bn1.running_var\", \"encoder.layer2.2.bn1.num_batches_tracked\", \"encoder.layer2.2.conv2.weight\", \"encoder.layer2.2.bn2.weight\", \"encoder.layer2.2.bn2.bias\", \"encoder.layer2.2.bn2.running_mean\", \"encoder.layer2.2.bn2.running_var\", \"encoder.layer2.2.bn2.num_batches_tracked\", \"encoder.layer2.3.conv1.weight\", \"encoder.layer2.3.bn1.weight\", \"encoder.layer2.3.bn1.bias\", \"encoder.layer2.3.bn1.running_mean\", \"encoder.layer2.3.bn1.running_var\", \"encoder.layer2.3.bn1.num_batches_tracked\", \"encoder.layer2.3.conv2.weight\", \"encoder.layer2.3.bn2.weight\", \"encoder.layer2.3.bn2.bias\", \"encoder.layer2.3.bn2.running_mean\", \"encoder.layer2.3.bn2.running_var\", \"encoder.layer2.3.bn2.num_batches_tracked\", \"encoder.layer3.0.conv1.weight\", \"encoder.layer3.0.bn1.weight\", \"encoder.layer3.0.bn1.bias\", \"encoder.layer3.0.bn1.running_mean\", \"encoder.layer3.0.bn1.running_var\", \"encoder.layer3.0.bn1.num_batches_tracked\", \"encoder.layer3.0.conv2.weight\", \"encoder.layer3.0.bn2.weight\", \"encoder.layer3.0.bn2.bias\", \"encoder.layer3.0.bn2.running_mean\", \"encoder.layer3.0.bn2.running_var\", \"encoder.layer3.0.bn2.num_batches_tracked\", \"encoder.layer3.0.downsample.0.weight\", \"encoder.layer3.0.downsample.1.weight\", \"encoder.layer3.0.downsample.1.bias\", \"encoder.layer3.0.downsample.1.running_mean\", \"encoder.layer3.0.downsample.1.running_var\", \"encoder.layer3.0.downsample.1.num_batches_tracked\", \"encoder.layer3.1.conv1.weight\", \"encoder.layer3.1.bn1.weight\", \"encoder.layer3.1.bn1.bias\", \"encoder.layer3.1.bn1.running_mean\", \"encoder.layer3.1.bn1.running_var\", \"encoder.layer3.1.bn1.num_batches_tracked\", \"encoder.layer3.1.conv2.weight\", \"encoder.layer3.1.bn2.weight\", \"encoder.layer3.1.bn2.bias\", \"encoder.layer3.1.bn2.running_mean\", \"encoder.layer3.1.bn2.running_var\", \"encoder.layer3.1.bn2.num_batches_tracked\", \"encoder.layer3.2.conv1.weight\", \"encoder.layer3.2.bn1.weight\", \"encoder.layer3.2.bn1.bias\", \"encoder.layer3.2.bn1.running_mean\", \"encoder.layer3.2.bn1.running_var\", \"encoder.layer3.2.bn1.num_batches_tracked\", \"encoder.layer3.2.conv2.weight\", \"encoder.layer3.2.bn2.weight\", \"encoder.layer3.2.bn2.bias\", \"encoder.layer3.2.bn2.running_mean\", \"encoder.layer3.2.bn2.running_var\", \"encoder.layer3.2.bn2.num_batches_tracked\", \"encoder.layer3.3.conv1.weight\", \"encoder.layer3.3.bn1.weight\", \"encoder.layer3.3.bn1.bias\", \"encoder.layer3.3.bn1.running_mean\", \"encoder.layer3.3.bn1.running_var\", \"encoder.layer3.3.bn1.num_batches_tracked\", \"encoder.layer3.3.conv2.weight\", \"encoder.layer3.3.bn2.weight\", \"encoder.layer3.3.bn2.bias\", \"encoder.layer3.3.bn2.running_mean\", \"encoder.layer3.3.bn2.running_var\", \"encoder.layer3.3.bn2.num_batches_tracked\", \"encoder.layer3.4.conv1.weight\", \"encoder.layer3.4.bn1.weight\", \"encoder.layer3.4.bn1.bias\", \"encoder.layer3.4.bn1.running_mean\", \"encoder.layer3.4.bn1.running_var\", \"encoder.layer3.4.bn1.num_batches_tracked\", \"encoder.layer3.4.conv2.weight\", \"encoder.layer3.4.bn2.weight\", \"encoder.layer3.4.bn2.bias\", \"encoder.layer3.4.bn2.running_mean\", \"encoder.layer3.4.bn2.running_var\", \"encoder.layer3.4.bn2.num_batches_tracked\", \"encoder.layer3.5.conv1.weight\", \"encoder.layer3.5.bn1.weight\", \"encoder.layer3.5.bn1.bias\", \"encoder.layer3.5.bn1.running_mean\", \"encoder.layer3.5.bn1.running_var\", \"encoder.layer3.5.bn1.num_batches_tracked\", \"encoder.layer3.5.conv2.weight\", \"encoder.layer3.5.bn2.weight\", \"encoder.layer3.5.bn2.bias\", \"encoder.layer3.5.bn2.running_mean\", \"encoder.layer3.5.bn2.running_var\", \"encoder.layer3.5.bn2.num_batches_tracked\", \"encoder.layer4.0.conv1.weight\", \"encoder.layer4.0.bn1.weight\", \"encoder.layer4.0.bn1.bias\", \"encoder.layer4.0.bn1.running_mean\", \"encoder.layer4.0.bn1.running_var\", \"encoder.layer4.0.bn1.num_batches_tracked\", \"encoder.layer4.0.conv2.weight\", \"encoder.layer4.0.bn2.weight\", \"encoder.layer4.0.bn2.bias\", \"encoder.layer4.0.bn2.running_mean\", \"encoder.layer4.0.bn2.running_var\", \"encoder.layer4.0.bn2.num_batches_tracked\", \"encoder.layer4.0.downsample.0.weight\", \"encoder.layer4.0.downsample.1.weight\", \"encoder.layer4.0.downsample.1.bias\", \"encoder.layer4.0.downsample.1.running_mean\", \"encoder.layer4.0.downsample.1.running_var\", \"encoder.layer4.0.downsample.1.num_batches_tracked\", \"encoder.layer4.1.conv1.weight\", \"encoder.layer4.1.bn1.weight\", \"encoder.layer4.1.bn1.bias\", \"encoder.layer4.1.bn1.running_mean\", \"encoder.layer4.1.bn1.running_var\", \"encoder.layer4.1.bn1.num_batches_tracked\", \"encoder.layer4.1.conv2.weight\", \"encoder.layer4.1.bn2.weight\", \"encoder.layer4.1.bn2.bias\", \"encoder.layer4.1.bn2.running_mean\", \"encoder.layer4.1.bn2.running_var\", \"encoder.layer4.1.bn2.num_batches_tracked\", \"encoder.layer4.2.conv1.weight\", \"encoder.layer4.2.bn1.weight\", \"encoder.layer4.2.bn1.bias\", \"encoder.layer4.2.bn1.running_mean\", \"encoder.layer4.2.bn1.running_var\", \"encoder.layer4.2.bn1.num_batches_tracked\", \"encoder.layer4.2.conv2.weight\", \"encoder.layer4.2.bn2.weight\", \"encoder.layer4.2.bn2.bias\", \"encoder.layer4.2.bn2.running_mean\", \"encoder.layer4.2.bn2.running_var\", \"encoder.layer4.2.bn2.num_batches_tracked\". \n\tsize mismatch for decoder.blocks.x_0_0.conv1.0.weight: copying a param with shape torch.Size([256, 768, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1920, 3, 3]).\n\tsize mismatch for decoder.blocks.x_0_1.conv1.0.weight: copying a param with shape torch.Size([128, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 736, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.0.weight: copying a param with shape torch.Size([128, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 800, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv1.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.0.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([240, 240, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_1_1.conv2.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([240]).\n\tsize mismatch for decoder.blocks.x_0_2.conv1.0.weight: copying a param with shape torch.Size([64, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 368, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 400, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_1_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 320, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_2_2.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for decoder.blocks.x_0_3.conv1.0.weight: copying a param with shape torch.Size([32, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 192, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.0.weight: copying a param with shape torch.Size([64, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 176, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_1_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.0.weight: copying a param with shape torch.Size([64, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 144, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_2_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.0.weight: copying a param with shape torch.Size([64, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 112, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv1.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.0.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 32, 3, 3]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for decoder.blocks.x_3_3.conv2.1.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32])."
     ]
    }
   ],
   "source": [
    "image_path = \"/notebooks/image_segmentation/network/image_data/train/images/patient_116.png\"\n",
    "mask_path = \"/notebooks/image_segmentation/network/image_data/train/masks/segmentation_116.png\" \n",
    "model_path = \"/notebooks/Testing/CV-131/MODEL-UnetPlusPlusresnet34CV-131_FINAL.pth\" \n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER_NAME,           # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    in_channels=3,                        # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                            # model output channels (number of classes in your dataset)\n",
    ")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "def predict_image(model, image, mask): \n",
    "\n",
    "    if type(image) == str: \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(mask_path)\n",
    "    \n",
    "        image, mask = convert_to_torch(image, mask)\n",
    "    \n",
    "    out = model(image.unsqueeze(0)) \n",
    "\n",
    "    segment_map = torch.sigmoid(out).squeeze(0).detach()\n",
    "    segment_map = (segment_map > 0.5) * 1\n",
    "    \n",
    "    plot_image_and_mask(image, mask)\n",
    "    plot_image_and_mask(image, segment_map)\n",
    "    \n",
    "#predict_image(model, image_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37722568-cb5a-48b7-8371-dbe22f52cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "\n",
    "for image, mask in DataLoader(valDataset, batch_size=1, shuffle=False, num_workers=0): \n",
    "    predict_image(model, image.squeeze(0), mask.squeeze(0))\n",
    "    print(\"-----------------------\")\n",
    "    count += 1\n",
    "    if count == 50:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
